name: Pipeline RAG MINEDUC - Producci√≥n

on:
  schedule:
    # Domingos 2 AM UTC (11 PM Chile S√°bado)
    - cron: '0 2 * * 0'
  
  workflow_dispatch:
    inputs:
      force_full_sync:
        description: 'Forzar sincronizaci√≥n completa'
        type: boolean
        default: false
      force_reindex:
        description: 'Forzar reindexaci√≥n HNSW'
        type: boolean
        default: false
      skip_validation:
        description: 'Saltar validaci√≥n (solo para debugging)'
        type: boolean
        default: false
      dry_run:
        description: 'Modo prueba (no escribe en BD)'
        type: boolean
        default: false

env:
  PYTHON_VERSION: '3.11'
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
  ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
  AI_EXTRACTION_ENABLED: 'true'

permissions:
  contents: read
  actions: write

jobs:
  # ============================================
  # FASE 0: Pre-flight Checks
  # ============================================
  
  preflight:
    name: "üîç Pre-flight: Verificar Sistema"
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      system_healthy: ${{ steps.health.outputs.healthy }}
      can_proceed: ${{ steps.health.outputs.can_proceed }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Instalar dependencias m√≠nimas
        run: pip install supabase python-dotenv
      
      - name: Verificar salud del sistema
        id: health
        run: |
          python - <<'PYTHON'
          import os
          from supabase import create_client
          
          supabase = create_client(
              os.getenv('SUPABASE_URL'),
              os.getenv('SUPABASE_SERVICE_ROLE_KEY')
          )
          
          # Verificar conectividad
          try:
              result = supabase.table('documentos_oficiales').select('id').limit(1).execute()
              print("‚úÖ Conexi√≥n Supabase OK")
              healthy = True
          except Exception as e:
              print(f"‚ùå Error Supabase: {e}")
              healthy = False
          
          # Verificar √≠ndices cr√≠ticos (v√≠a RPC)
          try:
              indices = supabase.rpc('verificar_indice_hnsw_existe').execute()
              if indices.data and indices.data.get('existe'):
                  print("‚úÖ √çndice HNSW presente")
              else:
                  print("‚ö†Ô∏è √çndice HNSW faltante (se crear√°)")
          except:
              pass
          
          # Output
          print(f"::set-output name=healthy::{str(healthy).lower()}")
          print(f"::set-output name=can_proceed::{str(healthy).lower()}")
          PYTHON
      
      - name: Bloquear si sistema no est√° saludable
        if: steps.health.outputs.healthy == 'false'
        run: |
          echo "‚ùå Sistema no est√° operativo - abortando pipeline"
          exit 1

  # ============================================
  # FASE 1: Extracci√≥n
  # ============================================
  
  extract:
    name: "üì• FASE 1: Extracci√≥n Documentos"
    runs-on: ubuntu-latest
    needs: preflight
    if: needs.preflight.outputs.can_proceed == 'true'
    timeout-minutes: 30
    outputs:
      has_changes: ${{ steps.monitor.outputs.has_changes }}
      nuevos: ${{ steps.monitor.outputs.nuevos }}
      actualizados: ${{ steps.monitor.outputs.actualizados }}
      
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Deno
        uses: denoland/setup-deno@v1
        with:
          deno-version: v1.40.x
      
      - name: Monitorear documentos oficiales
        id: monitor
        run: |
          response=$(curl -s -X POST \
            "${{ secrets.SUPABASE_URL }}/functions/v1/monitor-documentos-oficiales" \
            -H "Authorization: Bearer ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}" \
            -H "Content-Type: application/json" \
            -d "{\"force\": ${{ github.event.inputs.force_full_sync || false }}}")
          
          # Guardar respuesta completa
          echo "$response" > monitor_response.json
          
          # Validar respuesta
          if echo "$response" | jq -e '.error' > /dev/null; then
            echo "‚ùå Edge Function error: $(echo "$response" | jq -r '.error')"
            echo "has_changes=false" >> $GITHUB_OUTPUT
            echo "nuevos=0" >> $GITHUB_OUTPUT
            echo "actualizados=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Extraer m√©tricas con validaci√≥n
          nuevos=$(echo "$response" | jq -r '.reporte.documentos_nuevos // 0')
          actualizados=$(echo "$response" | jq -r '.reporte.documentos_actualizados // 0')
          
          # Validar n√∫meros
          [[ "$nuevos" =~ ^[0-9]+$ ]] || nuevos=0
          [[ "$actualizados" =~ ^[0-9]+$ ]] || actualizados=0
          
          echo "nuevos=$nuevos" >> $GITHUB_OUTPUT
          echo "actualizados=$actualizados" >> $GITHUB_OUTPUT
          
          if [ $nuevos -gt 0 ] || [ $actualizados -gt 0 ]; then
            echo "has_changes=true" >> $GITHUB_OUTPUT
          else
            echo "has_changes=false" >> $GITHUB_OUTPUT
          fi
          
          # Summary
          echo "### üìä Fase 1: Extracci√≥n" >> $GITHUB_STEP_SUMMARY
          echo "- **Documentos nuevos:** $nuevos" >> $GITHUB_STEP_SUMMARY
          echo "- **Actualizados:** $actualizados" >> $GITHUB_STEP_SUMMARY
      
      - name: Upload monitor response
        uses: actions/upload-artifact@v4
        with:
          name: extract-response
          path: monitor_response.json
          retention-days: 7

  # ============================================
  # FASE 1.5: Verificar Storage
  # ============================================
  
  check_storage:
    name: "üîç FASE 1.5: Verificar Storage"
    runs-on: ubuntu-latest
    needs: [preflight, extract]
    if: |
      always() && 
      needs.preflight.outputs.can_proceed == 'true' &&
      (needs.extract.outputs.has_changes == 'true' || github.event.inputs.force_full_sync == 'true')
    timeout-minutes: 10
    outputs:
      docs_sin_archivo: ${{ steps.check.outputs.sin_archivo }}
      docs_verificados: ${{ steps.check.outputs.verificados }}
      
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Instalar dependencias
        run: pip install supabase python-dotenv
      
      - name: Verificar archivos en Storage
        id: check
        run: |
          python - <<'PYTHON'
          import os
          from supabase import create_client
          
          supabase = create_client(
              os.getenv('SUPABASE_URL'),
              os.getenv('SUPABASE_SERVICE_ROLE_KEY')
          )
          
          # Obtener documentos con storage_path
          docs = supabase.table('documentos_oficiales')\
              .select('id, titulo, storage_path')\
              .eq('etapa_actual', 'descargado')\
              .not_.is_('storage_path', 'null')\
              .execute().data or []
          
          print(f"üìã Verificando {len(docs)} documentos...")
          
          sin_archivo = []
          
          for doc in docs:
              try:
                  # Intentar descargar
                  supabase.storage.from_('documentos-mineduc').download(doc['storage_path'])
                  print(f"  ‚úÖ {doc['titulo'][:50]}")
              except Exception as e:
                  # Archivo no existe
                  print(f"  ‚ùå {doc['titulo'][:50]} - {str(e)[:50]}")
                  sin_archivo.append(doc)
          
          print(f"\nüìä Resultados:")
          print(f"  ‚úÖ Con archivo: {len(docs) - len(sin_archivo)}")
          print(f"  ‚ùå Sin archivo: {len(sin_archivo)}")
          
          # Outputs para GitHub Actions
          print(f"::set-output name=verificados::{len(docs)}")
          print(f"::set-output name=sin_archivo::{len(sin_archivo)}")
          
          if sin_archivo:
              print(f"\nüîß Marcando {len(sin_archivo)} documentos para re-descarga...")
              
              for doc in sin_archivo:
                  try:
                      supabase.table('documentos_oficiales').update({
                          'etapa_actual': 'pendiente',
                          'metadata': {
                              'requiere_redownload': True,
                              'storage_path_invalido': doc['storage_path'],
                              'marcado_para_redownload': True
                          }
                      }).eq('id', doc['id']).execute()
                      print(f"  ‚úÖ Marcado: {doc['titulo'][:40]}")
                  except Exception as e:
                      print(f"  ‚ö†Ô∏è Error marcando {doc['id']}: {str(e)[:50]}")
              
              print(f"\n‚úÖ Marcados exitosamente")
              print(f"üì¢ RECOMENDACI√ìN: Ejecutar Edge Function con force=true para re-descargar")
          PYTHON
      
      - name: Generar summary
        run: |
          echo "### üîç Fase 1.5: Verificaci√≥n Storage" >> $GITHUB_STEP_SUMMARY
          echo "- **Documentos verificados:** ${{ steps.check.outputs.verificados }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Sin archivo en Storage:** ${{ steps.check.outputs.sin_archivo }}" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ steps.check.outputs.sin_archivo }}" -gt 0 ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "‚ö†Ô∏è **Acci√≥n requerida:** ${{ steps.check.outputs.sin_archivo }} documentos marcados para re-descarga" >> $GITHUB_STEP_SUMMARY
            echo "üí° **Soluci√≥n:** Ejecutar workflow con \`force_full_sync=true\`" >> $GITHUB_STEP_SUMMARY
          fi

  # ============================================
  # FASE 2: Transform
  # ============================================
  
  transform:
    name: "üîÑ FASE 2: Transform con IA"
    runs-on: ubuntu-latest
    needs: [preflight, extract, check_storage]
    if: |
      always() && 
      needs.preflight.outputs.can_proceed == 'true' &&
      (needs.extract.outputs.has_changes == 'true' || github.event.inputs.force_full_sync == 'true')
    timeout-minutes: 30
    outputs:
      success: ${{ steps.transform.outputs.success }}
      transformed: ${{ steps.transform.outputs.count }}
      cost: ${{ steps.transform.outputs.cost }}
      
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Instalar dependencias
        run: |
          pip install -r scripts/pipeline-document-mineduc/requirements.txt
          sudo apt-get update && sudo apt-get install -y tesseract-ocr tesseract-ocr-spa
      
      - name: Ejecutar transformaci√≥n
        id: transform
        run: |
          # Ejecutar con output JSON estructurado
          python scripts/pipeline-document-mineduc/fase2_transform_multiproveedor.py \
            --export-json 2>&1 | tee transform.log
          
          # Verificar si se gener√≥ JSON
          if [ -f transform_metrics.json ]; then
            # Extraer de JSON (m√°s robusto)
            transformed=$(jq -r '.transformed' transform_metrics.json)
            cost=$(jq -r '.cost_usd' transform_metrics.json)
            success="true"
          else
            # Fallback a regex (legacy)
            transformed=$(grep -oP "Transformados: \K[0-9]+" transform.log || echo "0")
            cost=$(grep -oP "Costo total IA: \\$\K[0-9.]+" transform.log || echo "0")
            success="false"
          fi
          
          # Outputs
          echo "success=$success" >> $GITHUB_OUTPUT
          echo "count=$transformed" >> $GITHUB_OUTPUT
          echo "cost=$cost" >> $GITHUB_OUTPUT
          
          # Summary
          echo "### üîÑ Fase 2: Transform" >> $GITHUB_STEP_SUMMARY
          echo "- **Transformados:** $transformed" >> $GITHUB_STEP_SUMMARY
          echo "- **Costo IA:** \$$cost USD" >> $GITHUB_STEP_SUMMARY
      
      - name: Upload transform metrics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: transform-metrics
          path: |
            transform.log
            transform_metrics.json
          if-no-files-found: ignore
          retention-days: 30

  # ============================================
  # FASE 3: Load
  # ============================================
  
  load:
    name: "üì¶ FASE 3: Load Embeddings"
    runs-on: ubuntu-latest
    needs: [preflight, transform]
    if: |
      always() &&
      needs.preflight.outputs.can_proceed == 'true' &&
      needs.transform.outputs.transformed > 0
    timeout-minutes: 45
    outputs:
      success: ${{ steps.load.outputs.success }}
      loaded: ${{ steps.load.outputs.count }}
      tokens: ${{ steps.load.outputs.tokens }}
      cost: ${{ steps.load.outputs.cost }}
      
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Instalar dependencias
        run: pip install -r scripts/pipeline-document-mineduc/requirements.txt
      
      - name: Ejecutar carga de embeddings
        id: load
        run: |
          python scripts/pipeline-document-mineduc/fase3_load.py \
            --export-json 2>&1 | tee load.log
          
          # Extraer de JSON si existe
          if [ -f load_metrics.json ]; then
            loaded=$(jq -r '.loaded' load_metrics.json)
            tokens=$(jq -r '.tokens' load_metrics.json)
            cost=$(jq -r '.cost_usd' load_metrics.json)
            success="true"
          else
            # Fallback
            loaded=$(grep -oP "Cargados: \K[0-9]+" load.log || echo "0")
            tokens=$(grep -oP "Tokens: \K[0-9,]+" load.log | tr -d ',' || echo "0")
            cost=$(grep -oP "Costo: \\$\K[0-9.]+" load.log || echo "0")
            success="false"
          fi
          
          echo "success=$success" >> $GITHUB_OUTPUT
          echo "count=$loaded" >> $GITHUB_OUTPUT
          echo "tokens=$tokens" >> $GITHUB_OUTPUT
          echo "cost=$cost" >> $GITHUB_OUTPUT
          
          echo "### üì¶ Fase 3: Load" >> $GITHUB_STEP_SUMMARY
          echo "- **Cargados:** $loaded" >> $GITHUB_STEP_SUMMARY
          echo "- **Tokens:** $(printf "%'d" $tokens)" >> $GITHUB_STEP_SUMMARY
          echo "- **Costo:** \$$cost USD" >> $GITHUB_STEP_SUMMARY
      
      - name: Upload load metrics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: load-metrics
          path: |
            load.log
            load_metrics.json
          if-no-files-found: ignore
          retention-days: 30

  # ============================================
  # FASE 4: Validate
  # ============================================
  
  validate:
    name: "‚úÖ FASE 4: Validaci√≥n Calidad"
    runs-on: ubuntu-latest
    needs: [preflight, load]
    if: |
      always() &&
      needs.preflight.outputs.can_proceed == 'true' &&
      needs.load.outputs.loaded > 0 &&
      github.event.inputs.skip_validation != 'true'
    timeout-minutes: 20
    outputs:
      success: ${{ steps.validate.outputs.success }}
      validated: ${{ steps.validate.outputs.count }}
      quality: ${{ steps.validate.outputs.quality }}
      alertas: ${{ steps.validate.outputs.alertas }}
      
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Instalar dependencias
        run: pip install -r scripts/pipeline-document-mineduc/requirements.txt
      
      - name: Validar calidad integral
        id: validate
        run: |
          python scripts/pipeline-document-mineduc/fase4_validacion_calidad.py 2>&1 | tee validate.log
          
          # Extraer de JSON
          if [ -f validation_report.json ]; then
            validated=$(jq -r '.chunks.total' validation_report.json)
            quality=$(jq -r '.chunks.calidad_promedio' validation_report.json)
            alertas=$(jq -r '.alertas | length' validation_report.json)
            success="true"
          else
            validated=$(grep -oP "Total chunks: \K[0-9]+" validate.log || echo "0")
            quality_pct=$(grep -oP "Calidad: \K[0-9.]+%" validate.log | tr -d '%' || echo "0")
            quality=$(echo "scale=4; $quality_pct / 100" | bc -l || echo "0")
            alertas=$(grep -oP "ALERTAS \\(\K[0-9]+" validate.log || echo "0")
            success="false"
          fi
          
          echo "success=$success" >> $GITHUB_OUTPUT
          echo "count=$validated" >> $GITHUB_OUTPUT
          echo "quality=$quality" >> $GITHUB_OUTPUT
          echo "alertas=$alertas" >> $GITHUB_OUTPUT
          
          echo "### ‚úÖ Fase 4: Validaci√≥n" >> $GITHUB_STEP_SUMMARY
          echo "- **Chunks validados:** $validated" >> $GITHUB_STEP_SUMMARY
          echo "- **Calidad:** $(echo "$quality * 100" | bc)%" >> $GITHUB_STEP_SUMMARY
          echo "- **Alertas:** $alertas" >> $GITHUB_STEP_SUMMARY
      
      - name: Upload validation report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: validation-report
          path: validation_report.json
          if-no-files-found: ignore
          retention-days: 90

  # ============================================
  # FASE 5: Optimize
  # ============================================
  
  optimize:
    name: "‚ö° FASE 5: Optimizar √çndices"
    runs-on: ubuntu-latest
    needs: [preflight, validate]
    if: |
      always() &&
      needs.preflight.outputs.can_proceed == 'true' &&
      needs.validate.outputs.validated > 0
    timeout-minutes: 20
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Instalar dependencias
        run: pip install supabase python-dotenv
      
      - name: Optimizar √≠ndices HNSW
        run: |
          python scripts/pipeline-document-mineduc/fase5_optimize.py 2>&1 | tee optimize.log
          
          # Extraer m√©tricas
          chunks=$(grep -oP "Chunks indexados: \K[0-9,]+" optimize.log | tr -d ',' || echo "0")
          size=$(grep -oP "Tama√±o √≠ndice: ~\K[0-9.]+" optimize.log || echo "0")
          
          echo "### ‚ö° Fase 5: Optimizaci√≥n" >> $GITHUB_STEP_SUMMARY
          echo "- **Chunks indexados:** $(printf "%'d" $chunks)" >> $GITHUB_STEP_SUMMARY
          echo "- **Tama√±o √≠ndice:** ~${size} MB" >> $GITHUB_STEP_SUMMARY
        env:
          FORCE_REINDEX: ${{ github.event.inputs.force_reindex }}

  # ============================================
  # FASE 6: Metrics
  # ============================================
  
  metrics:
    name: "üìä FASE 6: Registrar M√©tricas"
    runs-on: ubuntu-latest
    needs: [extract, check_storage, transform, load, validate, optimize]
    if: always()
    timeout-minutes: 10
    outputs:
      estado: ${{ steps.record.outputs.estado }}
      total_cost: ${{ steps.costs.outputs.total }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Instalar dependencias
        run: pip install supabase python-dotenv
      
      - name: Calcular costos
        id: costs
        run: |
          cost_transform="${{ needs.transform.outputs.cost || '0' }}"
          cost_load="${{ needs.load.outputs.cost || '0' }}"
          total=$(echo "$cost_transform + $cost_load" | bc -l || echo "0")
          
          echo "total=$total" >> $GITHUB_OUTPUT
          echo "transform=$cost_transform" >> $GITHUB_OUTPUT
          echo "load=$cost_load" >> $GITHUB_OUTPUT
      
      - name: Registrar m√©tricas
        id: record
        run: |
          python scripts/pipeline-document-mineduc/fase6_metrics.py \
            --downloaded "${{ needs.extract.outputs.nuevos || '0' }}" \
            --transformed "${{ needs.transform.outputs.transformed || '0' }}" \
            --loaded "${{ needs.load.outputs.loaded || '0' }}" \
            --validated "${{ needs.validate.outputs.validated || '0' }}" \
            --quality "${{ needs.validate.outputs.quality || '0' }}" \
            --tokens "${{ needs.load.outputs.tokens || '0' }}" \
            --cost "${{ steps.costs.outputs.total }}" \
            --workflow-id "${{ github.run_id }}" \
            --export-json 2>&1 | tee metrics.log
          
          # Extraer estado
          estado=$(grep -oP "Estado: .+ \K[A-Z]+" metrics.log || echo "DESCONOCIDO")
          echo "estado=$estado" >> $GITHUB_OUTPUT
      
      - name: Upload metrics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-metrics
          path: metrics_report.json
          retention-days: 90
      
      - name: Generar resumen final
        run: |
          echo "## üìä RESUMEN PIPELINE ETL" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Fase | Resultado |" >> $GITHUB_STEP_SUMMARY
          echo "|------|-----------|" >> $GITHUB_STEP_SUMMARY
          echo "| Extract | ${{ needs.extract.outputs.nuevos || 0 }} nuevos, ${{ needs.extract.outputs.actualizados || 0 }} actualizados |" >> $GITHUB_STEP_SUMMARY
          echo "| Check Storage | ${{ needs.check_storage.outputs.verificados || 0 }} verificados, ${{ needs.check_storage.outputs.sin_archivo || 0 }} sin archivo |" >> $GITHUB_STEP_SUMMARY
          echo "| Transform | ${{ needs.transform.outputs.transformed || 0 }} docs (\$${{ needs.transform.outputs.cost || 0 }}) |" >> $GITHUB_STEP_SUMMARY
          echo "| Load | ${{ needs.load.outputs.loaded || 0 }} docs, ${{ needs.load.outputs.tokens || 0 }} tokens (\$${{ needs.load.outputs.cost || 0 }}) |" >> $GITHUB_STEP_SUMMARY
          echo "| Validate | ${{ needs.validate.outputs.validated || 0 }} chunks, calidad ${{ needs.validate.outputs.quality || 0 }}% |" >> $GITHUB_STEP_SUMMARY
          echo "| **TOTAL** | **\$${{ steps.costs.outputs.total }} USD** |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Estado:** ${{ steps.record.outputs.estado }}" >> $GITHUB_STEP_SUMMARY
          
          # Advertencia si hay archivos faltantes
          if [ "${{ needs.check_storage.outputs.sin_archivo || 0 }}" -gt 0 ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "‚ö†Ô∏è **ADVERTENCIA:** ${{ needs.check_storage.outputs.sin_archivo }} documentos sin archivo en Storage" >> $GITHUB_STEP_SUMMARY
            echo "üí° **Acci√≥n recomendada:** Re-ejecutar con \`force_full_sync=true\`" >> $GITHUB_STEP_SUMMARY
          fi

  # ============================================
  # Notificaciones
  # ============================================
  
  notify:
    name: "üì¢ Notificaci√≥n Final"
    runs-on: ubuntu-latest
    needs: [extract, check_storage, transform, load, validate, metrics]
    if: always()
    
    steps:
      - name: Determinar estado final
        id: status
        run: |
          if [ "${{ needs.validate.result }}" == "failure" ]; then
            estado="‚ùå FALL√ì"
            color="danger"
          elif [ "${{ needs.load.result }}" == "failure" ]; then
            estado="‚ùå FALL√ì"
            color="danger"
          elif [ "${{ needs.validate.outputs.alertas }}" -gt 5 ]; then
            estado="‚ö†Ô∏è ALERTAS"
            color="warning"
          else
            estado="‚úÖ EXITOSO"
            color="good"
          fi
          
          echo "estado=$estado" >> $GITHUB_OUTPUT
          echo "color=$color" >> $GITHUB_OUTPUT
      
      - name: Notificar Slack
        if: always()
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "${{ steps.status.outputs.estado }} Pipeline RAG MINEDUC",
              "attachments": [{
                "color": "${{ steps.status.outputs.color }}",
                "fields": [
                  {"title": "Nuevos", "value": "${{ needs.extract.outputs.nuevos || 0 }}", "short": true},
                  {"title": "Transformados", "value": "${{ needs.transform.outputs.transformed || 0 }}", "short": true},
                  {"title": "Cargados", "value": "${{ needs.load.outputs.loaded || 0 }}", "short": true},
                  {"title": "Costo", "value": "\$${{ needs.metrics.outputs.total_cost || 0 }}", "short": true},
                  {"title": "Workflow", "value": "<${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|#${{ github.run_number }}>", "short": false}
                ]
              }]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK