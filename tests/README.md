# Tests para ProfeFlow Pipeline ETL

Este directorio contiene tests completos para el pipeline ETL de ProfeFlow, incluyendo procesamiento de documentos, extracciÃ³n de rÃºbricas y Edge Functions.

## ğŸ“ Estructura de Tests

```
tests/
â”œâ”€â”€ conftest.py                 # ConfiguraciÃ³n global y fixtures
â”œâ”€â”€ pytest.ini                 # ConfiguraciÃ³n de pytest
â”œâ”€â”€ README.md                   # Esta documentaciÃ³n
â”œâ”€â”€ pipeline/                   # Tests del pipeline ETL
â”‚   â”œâ”€â”€ test_document_processor.py    # Tests del procesador de documentos
â”‚   â””â”€â”€ test_rubric_extractor.py      # Tests del extractor de rÃºbricas
â”œâ”€â”€ integration/                # Tests de integraciÃ³n
â”‚   â””â”€â”€ test_pipeline_complete.py     # Tests del pipeline completo
â””â”€â”€ unit/                       # Tests unitarios
    â””â”€â”€ test_edge_functions.py        # Tests de Edge Functions

```

## ğŸš€ Ejecutar Tests

### Todos los tests
```bash
pytest
```

### Tests por categorÃ­a
```bash
# Tests unitarios rÃ¡pidos
pytest -m unit

# Tests de integraciÃ³n
pytest -m integration

# Tests del pipeline ETL
pytest -m pipeline

# Tests de Edge Functions
pytest -m edge_functions
```

### Tests especÃ­ficos
```bash
# Solo procesador de documentos
pytest tests/pipeline/test_document_processor.py

# Solo extractor de rÃºbricas
pytest tests/pipeline/test_rubric_extractor.py

# Test especÃ­fico
pytest tests/pipeline/test_document_processor.py::TestDocumentProcessor::test_init_success
```

### Con cobertura
```bash
pytest --cov=scripts --cov-report=html
```

## ğŸ·ï¸ Markers Disponibles

- `@pytest.mark.unit` - Tests unitarios rÃ¡pidos
- `@pytest.mark.integration` - Tests de integraciÃ³n
- `@pytest.mark.slow` - Tests que tardan >5 segundos
- `@pytest.mark.api` - Tests que requieren APIs externas
- `@pytest.mark.pipeline` - Tests especÃ­ficos del pipeline
- `@pytest.mark.edge_functions` - Tests de Edge Functions
- `@pytest.mark.mock_only` - Tests solo con mocks

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno para Tests
```bash
# Archivo .env.test (opcional)
TESTING=true
SUPABASE_URL=https://test.supabase.co
SUPABASE_SERVICE_ROLE_KEY=test_key
OPENAI_API_KEY=test_openai_key
ANTHROPIC_API_KEY=test_anthropic_key
GITHUB_TOKEN=test_github_token
COHERE_API_KEY=test_cohere_key
```

### Dependencias de Testing
```bash
pip install pytest pytest-mock pytest-asyncio pytest-cov
```

## ğŸ“‹ Cobertura de Tests

### DocumentProcessor
- âœ… InicializaciÃ³n con/sin variables de entorno
- âœ… Procesamiento de documentos pendientes
- âœ… ExtracciÃ³n de texto con PyMuPDF
- âœ… OCR para documentos escaneados
- âœ… GeneraciÃ³n de embeddings
- âœ… Limpieza y optimizaciÃ³n de texto
- âœ… Manejo de errores y fallbacks

### RubricExtractor
- âœ… InicializaciÃ³n con mÃºltiples APIs
- âœ… IdentificaciÃ³n de secciones de rÃºbricas
- âœ… ExtracciÃ³n con Anthropic, OpenAI, GitHub Models, Cohere
- âœ… Cascada de fallback entre APIs
- âœ… Manejo de rate limits
- âœ… Guardado en base de datos
- âœ… Manejo de errores JSON

### Edge Functions
- âœ… GeneraciÃ³n de embeddings
- âœ… Monitoreo de documentos
- âœ… OptimizaciÃ³n vectorial
- âœ… AutenticaciÃ³n de servicio
- âœ… Manejo de errores

### Pipeline Completo
- âœ… Flujo ETL completo
- âœ… Monitoreo â†’ Procesamiento â†’ ExtracciÃ³n
- âœ… RecuperaciÃ³n de errores
- âœ… Rate limit handling
- âœ… Embedding generation flow

## ğŸ¯ Casos de Test Principales

### 1. Procesamiento de Documentos
```python
def test_procesamiento_completo_mock(processor, mock_supabase):
    """Test de integraciÃ³n con mocks completos"""
    # Configura documento, mock descarga, extracciÃ³n, embedding
    # Verifica procesamiento exitoso
```

### 2. ExtracciÃ³n de RÃºbricas
```python
def test_cascada_fallback_completa(extractor, sample_rubric_text):
    """Test cascada: Anthropic â†’ OpenAI â†’ GitHub â†’ Cohere"""
    # Simula fallos en orden hasta Ã©xito con Cohere
```

### 3. Pipeline ETL Completo
```python
def test_complete_etl_pipeline_simulation():
    """Test simulaciÃ³n completa del pipeline ETL"""
    # EXTRACT: Monitoreo â†’ TRANSFORM: Procesamiento â†’ LOAD: RÃºbricas
```

## ğŸ› Debugging Tests

### Ejecutar con debugging
```bash
# Verbose output
pytest -v -s

# Solo fallos
pytest --tb=short

# Parar en primer fallo
pytest -x

# Ejecutar test especÃ­fico con debugging
pytest -v -s tests/pipeline/test_document_processor.py::TestDocumentProcessor::test_init_success
```

### Logs durante tests
```bash
# Ver logs de la aplicaciÃ³n
pytest --log-cli-level=DEBUG

# Capturar prints
pytest -s
```

## ğŸ“Š MÃ©tricas de Tests

### Tiempo de EjecuciÃ³n Esperado
- Tests unitarios: < 1 segundo cada uno
- Tests de integraciÃ³n: 2-5 segundos cada uno
- Pipeline completo: 5-10 segundos

### Cobertura Objetivo
- Procesador de documentos: >90%
- Extractor de rÃºbricas: >90%
- Edge Functions: >80%
- Pipeline completo: >85%

## ğŸ”„ CI/CD Integration

### GitHub Actions
```yaml
- name: Run Tests
  run: |
    pytest -m "not slow" --cov=scripts
    pytest -m integration --maxfail=1
```

### Pre-commit Hooks
```bash
# Ejecutar tests rÃ¡pidos antes de commit
pytest -m "unit and not slow" --maxfail=3
```

## ğŸ†˜ Troubleshooting

### Errores Comunes

1. **ImportError en scripts**
   ```bash
   # Asegurar que el path estÃ¡ configurado
   export PYTHONPATH="${PYTHONPATH}:$(pwd)/scripts/pipeline-document-mineduc"
   ```

2. **Tests lentos**
   ```bash
   # Ejecutar solo tests rÃ¡pidos
   pytest -m "not slow"
   ```

3. **Fallos de mocks**
   ```bash
   # Verificar que los mocks estÃ¡n configurados correctamente
   pytest -v -s tests/pipeline/test_document_processor.py::test_init_success
   ```

### Logs Ãštiles
- Tests fallidos: `pytest --tb=long`
- Cobertura detallada: `pytest --cov-report=term-missing`
- Tiempo de ejecuciÃ³n: `pytest --durations=10`