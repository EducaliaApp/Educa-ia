# MLOps Pipeline Review - ProfeFlow ETL

## Current Pipeline Architecture

### ‚úÖ **What's Working Well**

#### 1. **Data Ingestion**
- ‚úÖ Automated monitoring of official sources (DocenteM√°s, CPEIP)
- ‚úÖ Deduplication via content hashing
- ‚úÖ Metadata extraction and classification
- ‚úÖ Weekly scheduled execution

#### 2. **Data Processing**
- ‚úÖ PDF text extraction with OCR fallback
- ‚úÖ Text cleaning and normalization
- ‚úÖ Content relevance filtering
- ‚úÖ In-memory processing (cost-optimized)

#### 3. **Vector Embeddings**
- ‚úÖ OpenAI embeddings generation
- ‚úÖ PostgreSQL pg_vector storage
- ‚úÖ Edge Function integration
- ‚úÖ Fallback mechanisms

#### 4. **Data Quality**
- ‚úÖ Validation step in pipeline
- ‚úÖ Error tracking and logging
- ‚úÖ Quality score calculation
- ‚úÖ Critical error detection

#### 5. **CI/CD Integration**
- ‚úÖ GitHub Actions workflow
- ‚úÖ Automated testing
- ‚úÖ Artifact storage
- ‚úÖ Metrics tracking

---

## ‚ö†Ô∏è **MLOps Gaps & Recommendations**

### 1. **Data Versioning** ‚ùå
**Current**: No versioning of processed data
**Recommendation**: 
```sql
ALTER TABLE documentos_oficiales ADD COLUMN version INTEGER DEFAULT 1;
ALTER TABLE documentos_oficiales ADD COLUMN version_timestamp TIMESTAMP;
CREATE INDEX idx_documentos_version ON documentos_oficiales(contenido_hash, version);
```

### 2. **Embedding Model Versioning** ‚ùå
**Current**: No tracking of which embedding model was used
**Recommendation**:
```sql
ALTER TABLE documentos_oficiales ADD COLUMN embedding_model VARCHAR(50);
ALTER TABLE documentos_oficiales ADD COLUMN embedding_version VARCHAR(20);
-- Example: 'text-embedding-3-small', 'v1.0'
```

### 3. **Data Lineage** ‚ö†Ô∏è
**Current**: Basic tracking via `fuente` and `url_original`
**Recommendation**: Add comprehensive lineage
```sql
CREATE TABLE data_lineage (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    documento_id UUID REFERENCES documentos_oficiales(id),
    pipeline_run_id VARCHAR(100),
    stage VARCHAR(50), -- 'ingestion', 'processing', 'embedding', 'validation'
    timestamp TIMESTAMP DEFAULT NOW(),
    metadata JSONB
);
```

### 4. **Monitoring & Observability** ‚ö†Ô∏è
**Current**: Basic metrics in `metricas_pipeline_rag`
**Recommendation**: Enhanced monitoring
```sql
CREATE TABLE pipeline_metrics (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    run_id VARCHAR(100),
    stage VARCHAR(50),
    metric_name VARCHAR(100),
    metric_value NUMERIC,
    timestamp TIMESTAMP DEFAULT NOW(),
    metadata JSONB
);

-- Track: processing_time, embedding_latency, error_rate, quality_score
```

### 5. **Feature Store** ‚ùå
**Current**: No feature store for ML features
**Recommendation**: Add feature extraction
```sql
CREATE TABLE document_features (
    documento_id UUID PRIMARY KEY REFERENCES documentos_oficiales(id),
    word_count INTEGER,
    avg_sentence_length NUMERIC,
    readability_score NUMERIC,
    keyword_density JSONB,
    extracted_at TIMESTAMP DEFAULT NOW()
);
```

### 6. **A/B Testing Infrastructure** ‚ùå
**Current**: No support for testing different embedding models
**Recommendation**: Add experiment tracking
```sql
CREATE TABLE embedding_experiments (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    experiment_name VARCHAR(100),
    model_name VARCHAR(50),
    model_version VARCHAR(20),
    sample_size INTEGER,
    quality_metrics JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);
```

### 7. **Data Drift Detection** ‚ùå
**Current**: No drift detection
**Recommendation**: Add statistical monitoring
```python
# scripts/detect-data-drift.py
def detect_drift(current_batch, baseline):
    # Compare distributions
    # Check for schema changes
    # Monitor embedding quality
    # Alert on significant drift
    pass
```

### 8. **Model Registry** ‚ùå
**Current**: Hardcoded model names
**Recommendation**: Centralized model registry
```sql
CREATE TABLE model_registry (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    model_name VARCHAR(100),
    model_version VARCHAR(20),
    model_type VARCHAR(50), -- 'embedding', 'classification', 'extraction'
    provider VARCHAR(50), -- 'openai', 'gemini', 'cohere', 'anthropic'
    config JSONB,
    performance_metrics JSONB,
    is_active BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT NOW()
);
```

### 9. **Rollback Capability** ‚ùå
**Current**: No easy rollback mechanism
**Recommendation**: Implement versioned snapshots
```sql
CREATE TABLE data_snapshots (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    snapshot_date DATE,
    total_documents INTEGER,
    total_embeddings INTEGER,
    data_hash VARCHAR(64),
    storage_location TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);
```

### 10. **Cost Tracking** ‚ö†Ô∏è
**Current**: Basic tracking in logs
**Recommendation**: Detailed cost attribution
```sql
CREATE TABLE pipeline_costs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    run_id VARCHAR(100),
    stage VARCHAR(50),
    provider VARCHAR(50),
    api_calls INTEGER,
    tokens_used INTEGER,
    estimated_cost_usd NUMERIC(10,4),
    timestamp TIMESTAMP DEFAULT NOW()
);
```

---

## üéØ **Priority Improvements**

### High Priority (Implement Now)

1. **Add Embedding Model Tracking**
```python
# In document_processor.py
def _generar_embedding_supabase(self, documento_id: str, texto: str):
    # ... existing code ...
    
    # Track model used
    self.supabase.table('documentos_oficiales').update({
        'embedding_model': 'text-embedding-3-small',
        'embedding_version': 'v1.0',
        'embedding_generated_at': datetime.now().isoformat()
    }).eq('id', documento_id).execute()
```

2. **Add Pipeline Run Tracking**
```python
# In 00-monitor.py
class DocumentMonitor:
    def __init__(self):
        self.run_id = f"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
    def ejecutar_monitoreo_completo(self):
        # Log pipeline start
        self._log_pipeline_event('start', {'run_id': self.run_id})
        
        # ... existing code ...
        
        # Log pipeline end
        self._log_pipeline_event('end', {'run_id': self.run_id, 'results': resultados})
```

3. **Add Data Quality Metrics**
```python
def calculate_quality_metrics(documento):
    return {
        'text_length': len(documento['contenido_texto']),
        'has_embedding': documento.get('embedding') is not None,
        'extraction_method': 'pymupdf' if documento.get('tipo_contenido') != 'imagen_escaneada' else 'ocr',
        'quality_score': calculate_score(documento)
    }
```

### Medium Priority (Next Sprint)

4. **Implement Data Versioning**
5. **Add Comprehensive Monitoring**
6. **Create Feature Store**

### Low Priority (Future)

7. **A/B Testing Infrastructure**
8. **Advanced Drift Detection**
9. **Model Registry**

---

## üìä **Current vs. Ideal State**

| Component | Current | Ideal | Gap |
|-----------|---------|-------|-----|
| Data Ingestion | ‚úÖ Automated | ‚úÖ Automated | None |
| Data Processing | ‚úÖ Working | ‚úÖ Working | None |
| Vector Storage | ‚úÖ pg_vector | ‚úÖ pg_vector | None |
| Versioning | ‚ùå None | ‚úÖ Full | High |
| Monitoring | ‚ö†Ô∏è Basic | ‚úÖ Comprehensive | Medium |
| Lineage | ‚ö†Ô∏è Basic | ‚úÖ Full | Medium |
| Cost Tracking | ‚ö†Ô∏è Logs | ‚úÖ Database | Medium |
| Rollback | ‚ùå None | ‚úÖ Automated | High |
| Testing | ‚úÖ Unit | ‚úÖ Integration | Low |
| Documentation | ‚úÖ Good | ‚úÖ Excellent | Low |

---

## üöÄ **Implementation Plan**

### Week 1: Core MLOps Infrastructure
- [ ] Add embedding model tracking
- [ ] Implement pipeline run IDs
- [ ] Add data quality metrics
- [ ] Create monitoring dashboard

### Week 2: Versioning & Lineage
- [ ] Implement data versioning
- [ ] Add lineage tracking
- [ ] Create rollback mechanism
- [ ] Add cost tracking

### Week 3: Advanced Features
- [ ] Build feature store
- [ ] Implement drift detection
- [ ] Add model registry
- [ ] Create A/B testing framework

### Week 4: Testing & Documentation
- [ ] Integration tests
- [ ] Performance benchmarks
- [ ] Update documentation
- [ ] Team training

---

## üìà **Success Metrics**

### Data Quality
- ‚úÖ 95%+ documents successfully processed
- ‚úÖ 90%+ documents with embeddings
- ‚úÖ <5% error rate
- üéØ 100% data lineage coverage

### Performance
- ‚úÖ <5min average processing time per document
- ‚úÖ <2s embedding generation
- üéØ <1min end-to-end pipeline latency

### Cost Efficiency
- ‚úÖ $0 storage costs (text-only)
- ‚úÖ ~$0.01 per document (embeddings)
- üéØ <$50/month total pipeline cost

### Reliability
- ‚úÖ 99% uptime
- ‚úÖ 4-tier API fallback
- üéØ Zero data loss
- üéØ <1hr recovery time

---

## üîß **Quick Wins**

### Immediate Actions (< 1 day)

1. **Add Run ID to All Operations**
```python
RUN_ID = os.getenv('GITHUB_RUN_ID', f"local_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
```

2. **Track Embedding Model**
```python
EMBEDDING_MODEL = 'text-embedding-3-small'
EMBEDDING_VERSION = 'v1.0'
```

3. **Log All API Calls**
```python
def log_api_call(provider, endpoint, tokens, cost):
    logger.info(f"API_CALL: {provider} {endpoint} tokens={tokens} cost=${cost}")
```

4. **Add Health Checks**
```python
def health_check():
    checks = {
        'database': check_db_connection(),
        'storage': check_storage_access(),
        'apis': check_api_availability()
    }
    return all(checks.values())
```

---

## ‚úÖ **Conclusion**

The current pipeline is **functional and production-ready** but lacks some MLOps best practices:

**Strengths:**
- ‚úÖ Automated data ingestion
- ‚úÖ Robust error handling
- ‚úÖ Cost-optimized architecture
- ‚úÖ Vector embeddings working
- ‚úÖ CI/CD integration

**Areas for Improvement:**
- ‚ö†Ô∏è Data versioning
- ‚ö†Ô∏è Model tracking
- ‚ö†Ô∏è Comprehensive monitoring
- ‚ö†Ô∏è Rollback capability

**Recommendation**: Implement high-priority improvements (embedding tracking, run IDs, quality metrics) in the next sprint to achieve full MLOps maturity.
