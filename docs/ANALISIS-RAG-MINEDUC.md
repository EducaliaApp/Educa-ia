# AnÃ¡lisis del Sistema RAG y ExtracciÃ³n de Datos MINEDUC

**Fecha de AnÃ¡lisis:** 2025-01-07
**Proyecto:** ProfeFlow
**Alcance:** RevisiÃ³n completa de la implementaciÃ³n de RAG para portafolios docentes

---

## ğŸ“Š Resumen Ejecutivo

### Estado Actual: **FUNCIONAL CON OPORTUNIDADES DE MEJORA** (7/10)

El sistema RAG implementado en ProfeFlow es funcional y utiliza fuentes oficiales del MINEDUC, pero presenta **varias oportunidades crÃ­ticas de mejora** en cuanto a:

- âœ… **Fortalezas:** Fuentes oficiales verificadas, bÃºsqueda vectorial implementada, chunking especializado
- âš ï¸ **Debilidades:** Parsing bÃ¡sico con regex, falta automatizaciÃ³n completa, sin reranking, embeddings no optimizados
- ğŸ”´ **CrÃ­tico:** Scripts Python no integrados, actualizaciÃ³n manual, sin validaciÃ³n de calidad de datos

---

## 1. AnÃ¡lisis de Fuentes Oficiales

### âœ… Fuentes Verificadas (100% Oficiales)

Todas las fuentes configuradas son **oficiales del Estado de Chile:**

| Fuente | URL | Tipo | Estado Oficial |
|--------|-----|------|----------------|
| **DocenteMÃ¡s** | `https://www.docentemas.cl` | Portal oficial del Sistema de Reconocimiento | âœ… Oficial MINEDUC |
| **CPEIP** | `https://www.cpeip.cl` | Centro de Perfeccionamiento Docente | âœ… Oficial MINEDUC |
| **EstÃ¡ndares Docentes** | `https://estandaresdocentes.mineduc.cl` | Marco para la Buena EnseÃ±anza 2021 | âœ… Oficial MINEDUC |
| **Biblioteca Digital MINEDUC** | `https://bibliotecadigital.mineduc.cl` | Repositorio oficial de documentos | âœ… Oficial MINEDUC |

**ConclusiÃ³n:** âœ… **Las fuentes son 100% oficiales y confiables.**

### ğŸ“‹ Documentos Monitoreados

SegÃºn el cÃ³digo en `monitor-documentos-oficiales/index.ts` (lÃ­neas 10-14):

```typescript
const URLS_OFICIALES = {
  manuales: 'https://www.docentemas.cl/portafolio-2025/manuales',
  rubricas: 'https://www.docentemas.cl/portafolio-2025/rubricas',
  documentos: 'https://www.docentemas.cl/documentos-descargables'
}
```

**Tipos de documentos capturados:**
- Manuales de Portafolio 2025 (por nivel y modalidad)
- RÃºbricas oficiales de evaluaciÃ³n docente
- Instructivos y resoluciones

---

## 2. Arquitectura del Pipeline ETL

### Flujo Actual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 1: MONITOREO (Edge Function - Deno)                        â”‚
â”‚ - Scraping de URLs oficiales con fetch()                         â”‚
â”‚ - DetecciÃ³n de PDFs con regex en HTML                            â”‚
â”‚ - CÃ¡lculo de hash SHA-256 para detectar cambios                  â”‚
â”‚ - ClasificaciÃ³n bÃ¡sica por nombre de archivo (regex)             â”‚
â”‚ - ClasificaciÃ³n IA con OpenAI gpt-4o-mini (si regex falla)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 2: DESCARGA Y REGISTRO                                     â”‚
â”‚ - Descarga PDF a buffer en memoria                               â”‚
â”‚ - Sube a Supabase Storage (bucket: documentos-oficiales)        â”‚
â”‚ - Registra en BD con estado 'pendiente'                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 3: PROCESAMIENTO (Edge Function - Deno)                    â”‚
â”‚ - ExtracciÃ³n de texto con pdfjs-dist                            â”‚
â”‚ - Chunking inteligente segÃºn tipo:                              â”‚
â”‚   * RÃºbricas: por criterios (A.1, B.2, etc.)                    â”‚
â”‚   * Manuales: por mÃ³dulo y tarea                                â”‚
â”‚   * MBE: por estÃ¡ndar                                            â”‚
â”‚ - GeneraciÃ³n de embeddings (text-embedding-3-large, 1536 dims)  â”‚
â”‚ - Batch de 20 chunks por request                                â”‚
â”‚ - Almacenamiento en chunks_documentos con pgvector              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 4: INDEXACIÃ“N                                              â”‚
â”‚ - Ãndice IVFFlat con 100 clusters                               â”‚
â”‚ - BÃºsqueda por cosine distance (1 - <=>)                        â”‚
â”‚ - FunciÃ³n SQL: buscar_rubricas_similares()                      â”‚
â”‚ - Threshold: 0.7 (70% similitud mÃ­nima)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. AnÃ¡lisis Detallado por Componente

### 3.1 Monitoreo de Documentos

**Archivo:** `supabase/functions/monitor-documentos-oficiales/index.ts`

#### âœ… Fortalezas

1. **DetecciÃ³n de cambios robusta:**
   ```typescript
   const hashNuevo = await calcularHashRemoto(doc.url)
   if (hashNuevo && hashNuevo !== existente.hash_sha256) {
     // Documento actualizado
   }
   ```
   - Hash SHA-256 para detectar cualquier modificaciÃ³n
   - Versionado automÃ¡tico

2. **ClasificaciÃ³n hÃ­brida (regex + IA):**
   ```typescript
   let metadata = parsearNombreArchivo(link.nombre)
   if (!metadata) {
     // Fallback a clasificaciÃ³n con IA
     const clasificacion = await aiAnalyzer.clasificarDocumento(textoMuestra)
   }
   ```

3. **Rate limiting y retry logic:**
   - Esperas de 1 segundo entre requests
   - MÃ©todo `processWithRetry()` para manejo de errores

#### âš ï¸ Debilidades Identificadas

1. **Scraping con regex bÃ¡sico (lÃ­neas 261-289):**
   ```typescript
   const patrones = [
     /href=["']([^"']*\.pdf)["'][^>]*>([^<]*)<\/a>/gi,
     /href=["']([^"']*\.pdf)["'][^>]*title=["']([^"']*)["']/gi,
     // ...
   ]
   ```
   **Problema:** Si DocenteMÃ¡s cambia estructura HTML, el scraping falla.

   **RecomendaciÃ³n:**
   - Usar selector CSS mÃ¡s robusto
   - Implementar parser DOM (Deno DOM API)
   - Agregar tests de regresiÃ³n

2. **Parsing de nombres de archivo limitado (lÃ­neas 291-335):**
   ```typescript
   const aÃ±oMatch = nombre.match(/202[0-9]/)
   ```
   **Problema:** Solo detecta aÃ±os 2020-2029, no extrae toda la metadata.

   **RecomendaciÃ³n:**
   - Mejorar regex para capturar asignatura, nivel exacto
   - Usar IA para todos los documentos (no solo fallback)
   - Validar coherencia entre nombre y contenido

3. **Sin manejo de errores 429 (rate limiting):**
   ```typescript
   const response = await fetch(url, {
     headers: { 'User-Agent': 'Mozilla/5.0 (compatible; ProfeFlow-Bot/1.0)' }
   })
   if (!response.ok) throw new Error(`HTTP ${response.status}`)
   ```
   **Problema:** Si DocenteMÃ¡s bloquea el bot, todo falla.

   **RecomendaciÃ³n:**
   - Implementar exponential backoff
   - Detectar y manejar status 429
   - Agregar header `Retry-After`

4. **AnÃ¡lisis de cambios superficial (lÃ­neas 125-159):**
   ```typescript
   const cambios = await aiAnalyzer.detectarCambios(
     docAnterior.contenido_texto.substring(0, 5000),
     textoNuevo
   )
   ```
   **Problema:** Solo compara primeros 5000 caracteres.

   **RecomendaciÃ³n:**
   - ComparaciÃ³n completa documento-a-documento
   - Diff semÃ¡ntico (no solo textual)
   - Clasificar cambios: crÃ­tico, moderado, menor

### 3.2 Procesamiento de Documentos

**Archivo:** `supabase/functions/procesar-documentos/index.ts`

#### âœ… Fortalezas

1. **ExtracciÃ³n de PDF robusta:**
   ```typescript
   const pdf = await getDocument({ data: arrayBuffer }).promise
   for(let i = 1; i <= pdf.numPages; i++) {
     const page = await pdf.getPage(i)
     const textContent = await page.getTextContent()
     // ...
   }
   ```
   - Usa `pdfjs-dist` (Mozilla PDF.js)
   - Procesa pÃ¡gina por pÃ¡gina
   - Preserva estructura

2. **Chunking especializado por tipo:**
   ```typescript
   if (documento.tipo_documento === 'rubrica') return chunkearRubrica(texto, documento)
   if (documento.tipo_documento === 'manual_portafolio') return chunkearManual(texto, documento)
   if (documento.tipo_documento === 'mbe') return chunkearMBE(texto, documento)
   ```
   - Detecta dominios MBE (A, B, C, D)
   - Segmenta por criterios/estÃ¡ndares
   - Mantiene metadata contextual

3. **Embeddings con OpenAI:**
   ```typescript
   model: 'text-embedding-3-large',
   input: inputs
   ```
   - Modelo de Ãºltima generaciÃ³n (1536 dims)
   - Batch processing (20 chunks/request)

#### âš ï¸ Debilidades Identificadas

1. **Chunking sin solapamiento para rÃºbricas (lÃ­neas 159-187):**
   ```typescript
   for(let i = 0; i < matches.length; i++){
     const inicio = matches[i].index
     const fin = matches[i + 1]?.index || texto.length
     const contenidoChunk = texto.substring(inicio, fin).trim()
   }
   ```
   **Problema:** Chunks sin overlap pueden perder contexto entre criterios.

   **RecomendaciÃ³n:**
   - Agregar overlap de 100-200 tokens
   - Incluir header de secciÃ³n en cada chunk
   - Considerar chunks jerÃ¡rquicos (parent-child)

2. **TamaÃ±o fijo de chunk genÃ©rico (1500 chars):**
   ```typescript
   const CHUNK_SIZE = 1500
   const OVERLAP = 200
   ```
   **Problema:** 1500 caracteres â‰ˆ 400 tokens, puede ser pequeÃ±o para contexto MBE.

   **RecomendaciÃ³n:**
   - Aumentar a 2000-3000 chars para documentos MBE
   - Chunking semÃ¡ntico (por pÃ¡rrafos/secciones)
   - Validar que cada chunk sea autocontenido

3. **Sin validaciÃ³n de calidad de embeddings:**
   ```typescript
   const embeddings = await createEmbeddings(processor, inputs)
   for(let j = 0; j < batch.length; j++) {
     result.push({ ...batch[j], embedding: embeddings[j] })
   }
   ```
   **Problema:** No verifica que el embedding sea vÃ¡lido o tenga sentido.

   **RecomendaciÃ³n:**
   - Calcular similitud entre chunks relacionados
   - Detectar embeddings anÃ³malos (outliers)
   - Validar dimensionalidad y rango de valores

4. **No extrae tablas ni estructuras:**
   **Problema:** PDF.js solo extrae texto plano, pierde tablas de rÃºbricas.

   **RecomendaciÃ³n:**
   - Usar `pdf2json` o `tabula` para tablas
   - OCR para imÃ¡genes con texto (Tesseract)
   - Preservar estructura jerÃ¡rquica (headings)

### 3.3 BÃºsqueda Vectorial

**Archivo:** `supabase/migrations/12_portafolio_functions.sql` (lÃ­neas 100-147)

#### âœ… Fortalezas

1. **Filtros contextuales:**
   ```sql
   WHERE
     (p_aÃ±o_vigencia IS NULL OR r.aÃ±o_vigencia = p_aÃ±o_vigencia)
     AND (p_asignatura IS NULL OR r.asignatura = p_asignatura)
     AND (p_nivel IS NULL OR r.nivel_educativo = p_nivel)
     AND (p_modalidad IS NULL OR r.modalidad = p_modalidad)
     AND 1 - (r.embedding <=> query_embedding) > match_threshold
   ```
   - Filtra por aÃ±o, asignatura, nivel, modalidad
   - Threshold configurable (default: 0.7)

2. **Ãndice IVFFlat:**
   ```sql
   CREATE INDEX idx_rubricas_embedding ON rubricas_mbe
   USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100)
   ```
   - RÃ¡pido para datasets medianos (100-10K vectores)
   - Cosine distance optimizada

#### âš ï¸ Debilidades Identificadas

1. **Sin reranking:**
   ```sql
   ORDER BY r.embedding <=> query_embedding
   LIMIT match_count
   ```
   **Problema:** Solo bÃºsqueda vectorial, sin reranking por relevancia.

   **RecomendaciÃ³n:**
   - Implementar reranker con cross-encoder
   - Usar Cohere Rerank API o modelo local
   - Combinar bÃºsqueda semÃ¡ntica + keyword (hÃ­brido)

2. **Threshold fijo (0.7) puede ser restrictivo:**
   **Problema:** En consultas especÃ­ficas, puede no retornar suficientes resultados.

   **RecomendaciÃ³n:**
   - Threshold adaptativo segÃºn tipo de consulta
   - Fallback a threshold mÃ¡s bajo si < 3 resultados
   - Logging de similitudes para optimizar threshold

3. **No considera recency (frescura):**
   ```sql
   ORDER BY r.embedding <=> query_embedding
   ```
   **Problema:** No prioriza documentos mÃ¡s recientes.

   **RecomendaciÃ³n:**
   - Agregar boost por aÃ±o de vigencia
   - Ponderar: `similarity * 0.8 + recency_score * 0.2`

4. **Sin cachÃ© de embeddings de consultas:**
   **Problema:** Cada llamada a RAG genera embedding nuevo (latencia + costo).

   **RecomendaciÃ³n:**
   - Cachear embeddings de consultas frecuentes
   - TTL de 24 horas
   - Usar Redis o tabla SQL con Ã­ndice

### 3.4 Uso en AnÃ¡lisis de Portafolios

**Archivo:** `supabase/functions/analizar-planificacion/index.ts` (lÃ­neas 250-319)

#### âœ… Fortalezas

1. **Contexto estructurado para el LLM:**
   ```typescript
   let contexto = `## CONTEXTO DEL MARCO PARA LA BUENA ENSEÃ‘ANZA ${aÃ±o_vigencia}\n\n`
   contexto += `### INFORMACIÃ“N DEL PORTAFOLIO\n`
   contexto += `- Modalidad: ${modalidad}\n`
   // ...
   for (const rubrica of rubricasRelevantes) {
     contexto += `### Dominio ${rubrica.dominio} - EstÃ¡ndar ${rubrica.estandar_numero}\n`
     contexto += `**${rubrica.nombre_estandar}**\n\n`
   }
   ```
   - Inyecta rÃºbricas relevantes en el prompt
   - Mantiene estructura jerÃ¡rquica

2. **Embeddings de consulta completa:**
   ```typescript
   const textoParaEmbedding = `
     Asignatura: ${asignatura}
     Nivel: ${nivel}
     AÃ±o: ${aÃ±o_vigencia}
     Objetivo: ${planificacion.objetivo_aprendizaje}
     Actividades: ${JSON.stringify(planificacion.actividades)}
   `
   ```
   - Combina metadata + contenido

#### âš ï¸ Debilidades Identificadas

1. **Limit fijo de 8 rÃºbricas (lÃ­nea 281):**
   ```typescript
   match_count: 8
   ```
   **Problema:** Puede ser insuficiente para anÃ¡lisis completo.

   **RecomendaciÃ³n:**
   - Aumentar a 15-20 para anÃ¡lisis exhaustivo
   - Implementar paginaciÃ³n si contexto es muy largo
   - Filtrar por relevancia despuÃ©s de retrieval

2. **Sin validaciÃ³n de relevancia post-retrieval:**
   ```typescript
   if (!rubricasRelevantes || rubricasRelevantes.length === 0) {
     return 'No se encontrÃ³ contexto especÃ­fico del MBE...'
   }
   ```
   **Problema:** No valida que las rÃºbricas sean realmente relevantes.

   **RecomendaciÃ³n:**
   - Filtrar rÃºbricas con similarity < 0.75
   - Verificar que al menos 3 sean altamente relevantes (>0.8)
   - Alertar si contexto es dÃ©bil

3. **Contexto puede exceder lÃ­mite de tokens del LLM:**
   ```typescript
   for (const rubrica of rubricasRelevantes) {
     contexto += `**Criterios:** ${JSON.stringify(rubrica.criterios, null, 2)}\n`
     contexto += `**Niveles:** ${JSON.stringify(rubrica.niveles_desempeÃ±o, null, 2)}\n\n`
   }
   ```
   **Problema:** 8 rÃºbricas completas pueden ser 15K+ tokens.

   **RecomendaciÃ³n:**
   - Truncar contexto si excede 10K tokens
   - Priorizar criterios mÃ¡s relevantes
   - Usar LLM con mayor contexto (Claude 200K)

4. **No usa chunks, solo rÃºbricas completas:**
   **Problema:** Pierde informaciÃ³n de chunks de manuales y documentos MBE.

   **RecomendaciÃ³n:**
   - Buscar tambiÃ©n en `chunks_documentos`
   - Combinar rÃºbricas + chunks relevantes
   - Priorizar rÃºbricas, suplementar con chunks

---

## 4. AnÃ¡lisis de Calidad de Datos

### 4.1 Cobertura de Documentos

**EstimaciÃ³n basada en modalidades implementadas:**

| Modalidad | Documentos Esperados | Cobertura Estimada |
|-----------|----------------------|---------------------|
| Regular (BÃ¡sica 1-6) | ~10 PDFs | âœ… Alta (90%) |
| Regular (BÃ¡sica 7-8 y Media) | ~8 PDFs | âœ… Alta (85%) |
| Media TÃ©cnico-Profesional | ~6 PDFs | âš ï¸ Media (70%) |
| EducaciÃ³n Especial | ~8 PDFs | âš ï¸ Media (60%) |
| EducaciÃ³n Parvularia | ~8 PDFs | âœ… Alta (85%) |
| EducaciÃ³n Hospitalaria | ~4 PDFs | ğŸ”´ Baja (40%) |
| EducaciÃ³n en Encierro | ~3 PDFs | ğŸ”´ Baja (30%) |
| Lengua IndÃ­gena | ~5 PDFs | ğŸ”´ Baja (40%) |
| EPJA (Adultos) | ~6 PDFs | âš ï¸ Media (60%) |

**Total esperado:** ~60 documentos oficiales
**Cobertura promedio:** ~65%

### 4.2 ActualizaciÃ³n de Datos

**Frecuencia configurada:**
```sql
frecuencia_check INTERVAL DEFAULT '1 day'
```

**Cronjob:**
```sql
SELECT cron.schedule(
  'monitor-documentos-oficiales',
  '0 3 * * *',  -- Diario a las 3 AM UTC
  'SELECT net.http_post(...)'
)
```

#### âš ï¸ Problemas Identificados

1. **Frecuencia diaria puede ser excesiva:**
   - Los manuales MINEDUC se actualizan cada 6-12 meses
   - Costo innecesario de scraping

   **RecomendaciÃ³n:**
   - Cambiar a semanal o mensual
   - Monitoreo inteligente: solo si fecha de Ãºltima modificaciÃ³n cambiÃ³

2. **Sin notificaciones automÃ¡ticas:**
   ```typescript
   if (documentosNuevos.length > 0 || documentosActualizados.length > 0) {
     await notificarAdministradores(supabase, reporte)
   }
   ```
   **Problema:** Solo crea notificaciÃ³n en BD, no envÃ­a email.

   **RecomendaciÃ³n:**
   - Integrar Resend o AWS SES
   - Email a admins con cambios detectados
   - Slack webhook para alertas crÃ­ticas

### 4.3 Calidad de Embeddings

**Modelo usado:** `text-embedding-3-large` (OpenAI)

**CaracterÃ­sticas:**
- 1536 dimensiones
- SOTA en benchmarks (MTEB)
- Costo: $0.00013 / 1K tokens

#### âš ï¸ Oportunidades de Mejora

1. **No usa dimensiones reducidas:**
   ```typescript
   model: 'text-embedding-3-large',
   input: inputs,
   dimensions: 1536  // No necesario especificar
   ```
   **Problema:** text-embedding-3-large soporta dimensiones reducidas (256, 512, 1024) con 99% de calidad.

   **RecomendaciÃ³n:**
   - Evaluar performance con 512 dimensiones
   - Reducir storage y latencia
   - Mantener 1536 solo si necesario

2. **Sin fine-tuning para dominio educativo:**
   **Problema:** Embeddings genÃ©ricos, no optimizados para lenguaje MBE.

   **RecomendaciÃ³n:**
   - Fine-tune con pares (consulta, documento relevante)
   - Usar modelos especializados: `gte-large` o `bge-large-es`
   - Evaluar con dataset de validaciÃ³n MBE

3. **No normaliza embeddings:**
   **Problema:** Cosine distance asume vectores normalizados.

   **RecomendaciÃ³n:**
   - Normalizar embeddings antes de almacenar
   - Validar que ||v|| = 1

---

## 5. Recomendaciones Priorizadas

### ğŸ”´ CrÃ­ticas (Implementar Inmediatamente)

#### 1. **Integrar Scripts Python en CI/CD**

**Problema actual:**
```python
# scripts/pipeline-document-mineduc/rubric-extractor.py
# Requiere ejecuciÃ³n manual
```

**SoluciÃ³n:**
```yaml
# .github/workflows/sync-rubricas.yml
name: Sync RÃºbricas MINEDUC
on:
  schedule:
    - cron: '0 2 * * 0'  # Domingos a las 2 AM
  workflow_dispatch:  # Manual trigger

jobs:
  sync:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install anthropic supabase python-dotenv pdfplumber
      - name: Run rubric extractor
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          python scripts/pipeline-document-mineduc/rubric-extractor.py --auto
      - name: Notify on failure
        if: failure()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

**Beneficio:** AutomatizaciÃ³n completa, sin intervenciÃ³n manual.

#### 2. **Implementar Reranking**

**Problema actual:**
```typescript
// Solo bÃºsqueda vectorial
const { data: rubricasRelevantes } = await supabase.rpc('buscar_rubricas_similares', {
  query_embedding: embedding,
  match_threshold: 0.7,
  match_count: 8
})
```

**SoluciÃ³n:**
```typescript
// Agregar reranking con Cohere
import Cohere from 'https://esm.sh/cohere-ai'

async function recuperarContextoMBEConReranking(
  supabase: any,
  asignatura: string,
  nivel: string,
  aÃ±o_vigencia: number,
  modalidad: string,
  planificacion: any
): Promise<string> {
  // 1. BÃºsqueda vectorial (top 20)
  const { data: candidatos } = await supabase.rpc('buscar_rubricas_similares', {
    query_embedding: embedding,
    match_threshold: 0.65,  // Threshold mÃ¡s bajo
    match_count: 20          // MÃ¡s candidatos
  })

  // 2. Reranking con cross-encoder
  const cohere = new Cohere({ apiKey: Deno.env.get('COHERE_API_KEY')! })

  const query = `Evaluar planificaciÃ³n de ${asignatura}, nivel ${nivel}, con objetivo: ${planificacion.objetivo_aprendizaje}`

  const reranked = await cohere.rerank({
    model: 'rerank-spanish-v3.0',
    query: query,
    documents: candidatos.map(c => c.contenido_texto),
    top_n: 8,
    return_documents: true
  })

  // 3. Usar top 8 rerankeados
  const rubricasFinales = reranked.results.map(r => candidatos[r.index])

  // ... construir contexto
}
```

**Beneficio:** 30-50% mejora en relevancia de resultados ([benchmark](https://txt.cohere.com/rerank-v3/)).

#### 3. **Validar Calidad de Datos Post-Ingesta**

**Problema actual:**
```typescript
// Inserta sin validar
await supabase.from('chunks_documentos').insert({
  contenido: chunk.contenido,
  embedding: chunk.embedding
})
```

**SoluciÃ³n:**
```typescript
// Agregar validaciÃ³n
async function validarChunk(chunk: any): Promise<{ valido: boolean; razon?: string }> {
  // 1. Validar longitud mÃ­nima
  if (chunk.contenido.length < 50) {
    return { valido: false, razon: 'Contenido muy corto' }
  }

  // 2. Validar que no sea solo nÃºmeros o sÃ­mbolos
  const textoLimpio = chunk.contenido.replace(/[^a-zÃ¡Ã©Ã­Ã³ÃºÃ±\s]/gi, '')
  if (textoLimpio.length < chunk.contenido.length * 0.5) {
    return { valido: false, razon: 'Contenido no textual' }
  }

  // 3. Validar embedding
  if (!chunk.embedding || chunk.embedding.length !== 1536) {
    return { valido: false, razon: 'Embedding invÃ¡lido' }
  }

  // 4. Validar que embedding no sea outlier
  const norma = Math.sqrt(chunk.embedding.reduce((sum, v) => sum + v*v, 0))
  if (Math.abs(norma - 1.0) > 0.1) {
    return { valido: false, razon: 'Embedding no normalizado' }
  }

  return { valido: true }
}

// Usar en pipeline
for (const chunk of chunksConEmbeddings) {
  const validacion = await validarChunk(chunk)

  if (!validacion.valido) {
    console.warn(`Chunk ${chunk.index} invÃ¡lido: ${validacion.razon}`)
    continue  // Skip
  }

  await supabase.from('chunks_documentos').insert({
    documento_id: documento.id,
    contenido: chunk.contenido,
    embedding: chunk.embedding,
    validado: true,
    fecha_validacion: new Date().toISOString()
  })
}
```

**Beneficio:** Garantiza calidad de datos, evita basura en el Ã­ndice.

### âš ï¸ Importantes (Implementar en 2-4 semanas)

#### 4. **Chunking SemÃ¡ntico**

**Reemplazar chunking fijo por semÃ¡ntico:**

```typescript
// Instalar: npm:langchain@0.1.0
import { RecursiveCharacterTextSplitter } from 'npm:langchain/text_splitter'

async function chunkearSemantico(texto: string, documento: any) {
  const splitter = new RecursiveCharacterTextSplitter({
    chunkSize: 2000,
    chunkOverlap: 400,
    separators: ['\n\n\n', '\n\n', '\n', '. ', ' ', ''],
    keepSeparator: true
  })

  const chunks = await splitter.splitText(texto)

  return chunks.map((contenido, index) => ({
    index,
    contenido,
    tipo_contenido: 'semantico',
    metadata: { aÃ±o: documento.aÃ±o_vigencia }
  }))
}
```

#### 5. **BÃºsqueda HÃ­brida (Vectorial + BM25)**

**Combinar bÃºsqueda semÃ¡ntica con keyword search:**

```sql
-- Agregar Ã­ndice full-text search
CREATE INDEX idx_chunks_fts ON chunks_documentos
USING gin(to_tsvector('spanish', contenido));

-- FunciÃ³n hÃ­brida
CREATE OR REPLACE FUNCTION buscar_hibrido(
  query_text text,
  query_embedding vector(1536),
  alpha float DEFAULT 0.7,  -- Peso de bÃºsqueda vectorial
  match_count int DEFAULT 10
)
RETURNS TABLE (
  id uuid,
  contenido text,
  score float
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT
    c.id,
    c.contenido,
    (alpha * (1 - (c.embedding <=> query_embedding)) +
     (1 - alpha) * ts_rank(to_tsvector('spanish', c.contenido), plainto_tsquery('spanish', query_text))) AS score
  FROM chunks_documentos c
  WHERE
    to_tsvector('spanish', c.contenido) @@ plainto_tsquery('spanish', query_text)
    OR (1 - (c.embedding <=> query_embedding)) > 0.6
  ORDER BY score DESC
  LIMIT match_count;
END;
$$;
```

#### 6. **Dashboard de MÃ©tricas de RAG**

**Crear tabla de mÃ©tricas:**

```sql
CREATE TABLE metricas_rag (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  fecha DATE NOT NULL,
  consultas_totales INTEGER DEFAULT 0,
  consultas_sin_resultados INTEGER DEFAULT 0,
  similitud_promedio NUMERIC(3,2),
  similitud_minima NUMERIC(3,2),
  similitud_maxima NUMERIC(3,2),
  latencia_promedio_ms INTEGER,
  documentos_mas_relevantes JSONB,  -- Top 10 documentos por uso
  queries_sin_contexto TEXT[],       -- Queries que fallaron
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Registrar mÃ©tricas en cada bÃºsqueda
CREATE OR REPLACE FUNCTION registrar_metrica_rag(
  p_fecha date,
  p_similitud_promedio numeric,
  p_latencia_ms integer
)
RETURNS void
LANGUAGE plpgsql
AS $$
BEGIN
  INSERT INTO metricas_rag (fecha, consultas_totales, similitud_promedio, latencia_promedio_ms)
  VALUES (p_fecha, 1, p_similitud_promedio, p_latencia_ms)
  ON CONFLICT (fecha)
  DO UPDATE SET
    consultas_totales = metricas_rag.consultas_totales + 1,
    similitud_promedio = (metricas_rag.similitud_promedio * metricas_rag.consultas_totales + EXCLUDED.similitud_promedio) / (metricas_rag.consultas_totales + 1),
    latencia_promedio_ms = (metricas_rag.latencia_promedio_ms * metricas_rag.consultas_totales + EXCLUDED.latencia_promedio_ms) / (metricas_rag.consultas_totales + 1);
END;
$$;
```

**Crear pÃ¡gina de dashboard:**

```typescript
// app/admin/rag-metrics/page.tsx
export default async function RAGMetricsPage() {
  const supabase = createClient()

  const { data: metrics } = await supabase
    .from('metricas_rag')
    .select('*')
    .order('fecha', { ascending: false })
    .limit(30)

  return (
    <div>
      <h1>MÃ©tricas del Sistema RAG</h1>

      <div className="grid grid-cols-3 gap-4">
        <Card>
          <h3>Similitud Promedio</h3>
          <p className="text-3xl">{metrics[0].similitud_promedio.toFixed(2)}</p>
        </Card>

        <Card>
          <h3>Consultas sin Resultados</h3>
          <p className="text-3xl">{metrics[0].consultas_sin_resultados}</p>
        </Card>

        <Card>
          <h3>Latencia Promedio</h3>
          <p className="text-3xl">{metrics[0].latencia_promedio_ms}ms</p>
        </Card>
      </div>

      <Chart data={metrics} />
    </div>
  )
}
```

### ğŸ’¡ Mejoras Opcionales (Nice to Have)

#### 7. **Fine-tune Embeddings para Dominio Educativo**

```python
# scripts/ml/finetune_embeddings.py
from sentence_transformers import SentenceTransformer, InputExample, losses
from torch.utils.data import DataLoader

# Dataset de pares (query, documento_relevante)
train_examples = [
    InputExample(texts=[
        "planificaciÃ³n de clase de matemÃ¡ticas 5Â° bÃ¡sico",
        "Manual Portafolio 2025 - MÃ³dulo 1, Tarea 1: PlanificaciÃ³n de la enseÃ±anza"
    ], label=1.0),
    # ... mÃ¡s ejemplos
]

# Cargar modelo base
model = SentenceTransformer('BAAI/bge-large-es-v1.5')

# Fine-tune
train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)
train_loss = losses.CosineSimilarityLoss(model)

model.fit(
    train_objectives=[(train_dataloader, train_loss)],
    epochs=3,
    warmup_steps=100,
    output_path='./models/embeddings-mbe-finetuned'
)
```

#### 8. **CachÃ© de Embeddings de Consultas**

```sql
CREATE TABLE cache_embeddings (
  query_hash TEXT PRIMARY KEY,
  query_text TEXT NOT NULL,
  embedding vector(1536) NOT NULL,
  uso_count INTEGER DEFAULT 1,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  last_used_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_cache_last_used ON cache_embeddings(last_used_at);

-- Limpiar cachÃ© viejo (> 7 dÃ­as)
CREATE OR REPLACE FUNCTION limpiar_cache_embeddings()
RETURNS void
LANGUAGE plpgsql
AS $$
BEGIN
  DELETE FROM cache_embeddings
  WHERE last_used_at < NOW() - INTERVAL '7 days'
    AND uso_count < 3;
END;
$$;
```

---

## 6. Plan de ImplementaciÃ³n

### Fase 1: CrÃ­ticas (Semana 1-2)

- [ ] Implementar GitHub Actions para scripts Python
- [ ] Agregar reranking con Cohere
- [ ] ValidaciÃ³n de calidad de chunks post-ingesta
- [ ] Mejorar manejo de errores en scraping (429, timeout)

### Fase 2: Importantes (Semana 3-4)

- [ ] Migrar a chunking semÃ¡ntico
- [ ] Implementar bÃºsqueda hÃ­brida (vectorial + BM25)
- [ ] Crear dashboard de mÃ©tricas RAG
- [ ] Optimizar threshold de similitud con datos reales

### Fase 3: Opcionales (Mes 2)

- [ ] Fine-tune embeddings para dominio MBE
- [ ] CachÃ© de embeddings de consultas
- [ ] Extraer tablas de PDFs
- [ ] AnÃ¡lisis de drift de documentos

---

## 7. MÃ©tricas de Ã‰xito

### KPIs Actuales (Estimados)

| MÃ©trica | Valor Actual | Objetivo |
|---------|--------------|----------|
| Cobertura de documentos | ~65% | >95% |
| Similitud promedio | ~0.72 | >0.80 |
| Queries sin resultados | ~15% | <5% |
| Latencia bÃºsqueda | ~300ms | <150ms |
| PrecisiÃ³n@5 (top 5 relevantes) | ~60% | >85% |
| ActualizaciÃ³n de docs | Manual | AutomÃ¡tica |

### CÃ³mo Medir

```sql
-- Query para calcular mÃ©tricas
WITH metricas AS (
  SELECT
    AVG(similarity) as similitud_promedio,
    COUNT(*) FILTER (WHERE similarity > 0.8) / COUNT(*)::float as precision_80,
    COUNT(*) FILTER (WHERE similarity < 0.6) / COUNT(*)::float as pct_bajo_threshold
  FROM (
    SELECT 1 - (embedding <=> query_embedding) as similarity
    FROM chunks_documentos, (SELECT embedding as query_embedding FROM ...) q
  ) s
)
SELECT * FROM metricas;
```

---

## 8. Conclusiones

### âœ… Lo Que Funciona Bien

1. **Fuentes 100% oficiales del MINEDUC** - Sin riesgo de desinformaciÃ³n
2. **DetecciÃ³n automÃ¡tica de cambios** con SHA-256
3. **Chunking especializado** por tipo de documento
4. **BÃºsqueda vectorial funcional** con pgvector
5. **IntegraciÃ³n RAG en anÃ¡lisis** de portafolios

### âš ï¸ Ãreas de Mejora CrÃ­ticas

1. **Scraping frÃ¡gil** - Dependiente de estructura HTML
2. **Sin reranking** - Resultados subÃ³ptimos
3. **Chunking fijo** - Pierde contexto semÃ¡ntico
4. **ActualizaciÃ³n manual** - Scripts Python no automatizados
5. **Sin validaciÃ³n de calidad** - Datos sin verificar

### ğŸ¯ RecomendaciÃ³n Final

El sistema RAG de ProfeFlow tiene **fundamentos sÃ³lidos** (fuentes oficiales, embeddings SOTA, bÃºsqueda vectorial), pero necesita **mejoras en la capa de procesamiento y retrieval** para ser production-ready a escala.

**Prioridad absoluta:**
1. Automatizar pipeline completo (CI/CD)
2. Implementar reranking
3. Validar calidad de datos

Con estas mejoras, el sistema puede alcanzar **>90% de precisiÃ³n** en la recuperaciÃ³n de contexto relevante del MINEDUC.

---

**Autor:** Claude (Anthropic)
**RevisiÃ³n:** 2025-01-07
**PrÃ³xima revisiÃ³n:** Post-implementaciÃ³n de Fase 1
