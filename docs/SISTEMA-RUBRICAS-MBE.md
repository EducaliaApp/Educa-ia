# Sistema de R√∫bricas MBE 2025 - ProfeFlow

## üìã √çndice

1. [Introducci√≥n](#introducci√≥n)
2. [Arquitectura del Sistema](#arquitectura-del-sistema)
3. [Base de Datos](#base-de-datos)
4. [Motor de R√∫bricas](#motor-de-r√∫bricas)
5. [Evaluador de IA](#evaluador-de-ia)
6. [Edge Functions](#edge-functions)
7. [Gu√≠a de Uso](#gu√≠a-de-uso)
8. [Agregar Nuevas R√∫bricas](#agregar-nuevas-r√∫bricas)
9. [Ejemplos Completos](#ejemplos-completos)
10. [Troubleshooting](#troubleshooting)

---

## Introducci√≥n

El Sistema de R√∫bricas MBE 2025 es una implementaci√≥n completa del Marco para la Buena Ense√±anza (MBE) de Chile, dise√±ado para evaluar autom√°ticamente el trabajo docente usando Inteligencia Artificial.

### Caracter√≠sticas Principales

- ‚úÖ **Evaluaci√≥n autom√°tica** con Claude Sonnet 4 u OpenAI GPT-4
- ‚úÖ **4 niveles de desempe√±o**: Destacado (4.0), Competente (3.0), B√°sico (2.0), Insatisfactorio (1.0)
- ‚úÖ **Verificaci√≥n autom√°tica de l√≥gica**: AND/OR en condiciones
- ‚úÖ **Correcci√≥n autom√°tica**: Si la IA asigna un nivel incorrecto, el sistema lo corrige
- ‚úÖ **Estad√≠sticas comparativas**: Percentiles y promedios nacionales
- ‚úÖ **Feedback detallado**: Fortalezas, recomendaciones priorizadas, evidencias textuales
- ‚úÖ **Escalable**: F√°cil agregar nuevas r√∫bricas y m√≥dulos

---

## Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      FRONTEND (Next.js)                      ‚îÇ
‚îÇ  - Componentes de portafolio                                ‚îÇ
‚îÇ  - Hooks: useAIAnalysis                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚îÇ HTTP + JWT Bearer Token
                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              EDGE FUNCTIONS (Deno Runtime)                   ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  analizar-modulo1-tarea1/index.ts                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Autentica usuario                                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Carga contexto de tarea                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Inicializa RubricasEngine                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Inicializa IAEvaluator                            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Eval√∫a cada indicador                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Guarda resultados                                 ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  _shared/rubricas-engine.ts                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - cargarRubricas()                                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - evaluarIndicador()                                ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - construirPrompt()                                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - verificarLogica()                                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - enriquecerConEstadisticas()                       ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  _shared/ia-evaluator.ts                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - evaluar() ‚Üí Claude/GPT-4                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Retorna JSON estructurado                         ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚îÇ SQL Queries
                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  SUPABASE (PostgreSQL)                       ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  üìä rubricas_mbe                                             ‚îÇ
‚îÇ     - indicador_id, niveles_desempeno (JSONB)                ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  üìä evaluaciones_indicador                                   ‚îÇ
‚îÇ     - tarea_id, indicador_id, nivel_alcanzado, puntaje       ‚îÇ
‚îÇ     - condiciones_evaluadas (JSONB)                          ‚îÇ
‚îÇ     - recomendaciones (JSONB)                                ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  üìä estadisticas_indicadores                                 ‚îÇ
‚îÇ     - promedio_nacional, desviacion_estandar                 ‚îÇ
‚îÇ     - porcentajes por nivel                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Base de Datos

### Tabla: `rubricas_mbe`

Almacena las r√∫bricas oficiales del MBE 2025.

```sql
CREATE TABLE rubricas_mbe (
  id UUID PRIMARY KEY,
  indicador_id TEXT NOT NULL,              -- Ej: "M1_I1", "M2_I3"
  nombre_indicador TEXT NOT NULL,
  descripcion_general TEXT,

  -- Contexto
  a√±o_vigencia INTEGER DEFAULT 2025,
  nivel_educativo TEXT NOT NULL,           -- "general", "basica", "media"
  asignatura TEXT,                         -- NULL = generalista
  modalidad TEXT DEFAULT 'regular',

  -- M√≥dulo/Tarea
  modulo INTEGER CHECK (modulo IN (1,2,3)),
  tarea INTEGER,

  -- Ponderaci√≥n
  peso_porcentaje NUMERIC(5,2),

  -- Estructura de evaluaci√≥n (JSONB)
  niveles_desempeno JSONB NOT NULL,

  -- Metadata
  fuente_oficial TEXT,
  pagina_manual INTEGER,
  notas_aclaratorias TEXT,
  ejemplos TEXT[],

  -- Estado
  activo BOOLEAN DEFAULT TRUE,
  version TEXT DEFAULT '1.0',

  UNIQUE(indicador_id, a√±o_vigencia, nivel_educativo, COALESCE(asignatura, ''))
);
```

#### Estructura de `niveles_desempeno` (JSONB)

```json
{
  "destacado": {
    "nivel": "Destacado",
    "letra": "D",
    "puntaje": 4.0,
    "logica": "AND",
    "descripcion": "Descripci√≥n del nivel destacado...",
    "condiciones": [
      {
        "id": "D_1",
        "descripcion": "Primera condici√≥n",
        "tipo": "calidad",
        "requiere_evidencia": true,
        "criterios": {
          "palabras_clave": ["objetivo", "aprendizaje"],
          "longitud_minima": 50
        },
        "peso": 1.0
      }
    ],
    "notas": "Notas adicionales del nivel"
  },
  "competente": { ... },
  "basico": { ... },
  "insatisfactorio": { ... }
}
```

**L√≥gica de condiciones:**
- `"logica": "AND"` ‚Üí Deben cumplirse **TODAS** las condiciones
- `"logica": "OR"` ‚Üí Debe cumplirse **AL MENOS UNA** condici√≥n

### Tabla: `evaluaciones_indicador`

Almacena los resultados de evaluaciones de indicadores.

```sql
CREATE TABLE evaluaciones_indicador (
  id UUID PRIMARY KEY,
  tarea_id UUID REFERENCES tareas_portafolio(id),
  indicador_id TEXT NOT NULL,
  rubrica_id UUID REFERENCES rubricas_mbe(id),

  -- Resultado
  nivel_alcanzado TEXT CHECK (nivel_alcanzado IN ('Destacado', 'Competente', 'B√°sico', 'Insatisfactorio')),
  puntaje NUMERIC(3,1) CHECK (puntaje IN (4.0, 3.0, 2.0, 1.0)),

  -- Condiciones
  condiciones_cumplidas INTEGER,
  condiciones_totales INTEGER,
  condiciones_evaluadas JSONB,

  -- Feedback
  justificacion TEXT,
  para_siguiente_nivel TEXT,
  evidencias_textuales TEXT[],
  fortalezas TEXT[],
  recomendaciones JSONB,

  -- Correcciones
  correccion_aplicada BOOLEAN DEFAULT FALSE,
  nota_correccion TEXT,

  -- Estad√≠sticas
  promedio_nacional NUMERIC(3,2),
  desviacion_estandar NUMERIC(3,2),
  percentil INTEGER,

  -- Metadata
  modelo_ia TEXT,
  tokens_utilizados INTEGER,
  tiempo_evaluacion_ms INTEGER,

  UNIQUE(tarea_id, indicador_id)
);
```

### Tabla: `estadisticas_indicadores`

Estad√≠sticas agregadas para comparaci√≥n y benchmarking.

```sql
CREATE TABLE estadisticas_indicadores (
  id UUID PRIMARY KEY,
  indicador_id TEXT NOT NULL,
  a√±o INTEGER,
  nivel_educativo TEXT,
  asignatura TEXT,

  total_evaluaciones INTEGER,
  puntaje_promedio NUMERIC(3,2),
  desviacion_estandar NUMERIC(3,2),

  porcentaje_destacado NUMERIC(5,2),
  porcentaje_competente NUMERIC(5,2),
  porcentaje_basico NUMERIC(5,2),
  porcentaje_insatisfactorio NUMERIC(5,2),

  ultima_actualizacion TIMESTAMPTZ,

  UNIQUE(indicador_id, a√±o, nivel_educativo, COALESCE(asignatura, ''))
);
```

---

## Motor de R√∫bricas

El `RubricasEngine` es el coraz√≥n del sistema. Orquesta todo el proceso de evaluaci√≥n.

### M√©todos Principales

#### 1. `cargarRubricas(contexto)`

Carga las r√∫bricas relevantes seg√∫n el contexto educativo.

```typescript
const rubricasEngine = new RubricasEngine(supabase, 'contexto-evaluacion')

const rubricas = await rubricasEngine.cargarRubricas({
  a√±o: 2025,
  nivel_educativo: 'basica',
  asignatura: 'Lenguaje',
  modulo: 1,
  tarea: 1
})

// Retorna: Rubrica[]
```

**Filtros aplicados:**
- A√±o de vigencia
- Nivel educativo
- Asignatura (incluye generalistas con `asignatura: NULL`)
- M√≥dulo y tarea
- Solo r√∫bricas activas

#### 2. `evaluarIndicador(rubrica, contenido, iaEvaluator)`

Eval√∫a un indicador espec√≠fico usando IA.

```typescript
const iaEvaluator = new IAEvaluator({
  modelo: 'claude-sonnet-4',
  apiKey: process.env.ANTHROPIC_API_KEY!,
  temperatura: 0.3,
  maxTokens: 4000
})

const evaluacion = await rubricasEngine.evaluarIndicador(
  rubrica,        // Rubrica cargada
  contenidoDocente, // String con la respuesta del docente
  iaEvaluator     // Evaluador de IA
)

// Retorna: EvaluacionIndicador
```

**Proceso interno:**
1. Construye prompt especializado con la r√∫brica
2. Llama a IA (Claude o GPT-4)
3. Parsea respuesta JSON
4. Verifica l√≥gica de condiciones (AND/OR)
5. Corrige nivel si es necesario
6. Enriquece con estad√≠sticas
7. Retorna evaluaci√≥n completa

#### 3. `construirPrompt(rubrica, contenido)` (privado)

Genera un prompt especializado y estructurado:

```
# EVALUACI√ìN DE INDICADOR - SISTEMA DOCENTE CHILE

## CONTEXTO
Eres un evaluador experto del Sistema de Reconocimiento Profesional Docente...

## INDICADOR A EVALUAR
**ID:** M1_I1
**Nombre:** Identifica el aprendizaje que espera que sus estudiantes logren
...

## NIVELES DE DESEMPE√ëO
### üåü NIVEL DESTACADO (4.0 puntos)
Descripci√≥n...
**Condiciones (deben cumplirse TODAS):**
1. ...
2. ...

## CONTENIDO DEL/LA DOCENTE A EVALUAR
```
Respuesta del docente...
```

## REGLAS CR√çTICAS
- NO seas ben√©volo
- NO asumas: si no hay evidencia, no se cumple
- S√â ESTRICTO con l√≥gica AND
- CITA textualmente

## RESPONDE SOLO CON ESTE JSON:
{ ... }
```

#### 4. `verificarLogica(evaluacion, rubrica)` (privado)

Verifica que la IA haya aplicado correctamente la l√≥gica AND/OR.

**Ejemplo de correcci√≥n:**

```typescript
// IA asign√≥ "Destacado" pero solo cumpli√≥ 2 de 3 condiciones
// y la l√≥gica es AND ‚Üí el sistema corrige a "Competente"

{
  ...evaluacion,
  nivel_alcanzado: "Competente",
  puntaje: 3.0,
  correccion_aplicada: true,
  nota_correccion: "El nivel fue ajustado autom√°ticamente seg√∫n la l√≥gica de condiciones"
}
```

#### 5. `enriquecerConEstadisticas(evaluacion, rubrica)` (privado)

Agrega datos de comparaci√≥n nacional:

```typescript
{
  ...evaluacion,
  promedio_nacional: 2.8,
  desviacion_estandar: 0.6,
  percentil: 73  // Este docente est√° en el percentil 73
}
```

**C√°lculo de percentil:**
- Usa distribuci√≥n normal est√°ndar
- Z-score: `(puntaje - promedio) / desviacion`
- Funci√≥n erf() para conversi√≥n a percentil

---

## Evaluador de IA

El `IAEvaluator` abstrae la comunicaci√≥n con Claude y GPT-4.

### Inicializaci√≥n

```typescript
import { IAEvaluator } from '../_shared/ia-evaluator.ts'

// Opci√≥n 1: Claude Sonnet 4
const evaluatorClaude = new IAEvaluator({
  modelo: 'claude-sonnet-4',
  apiKey: Deno.env.get('ANTHROPIC_API_KEY')!,
  temperatura: 0.3,  // Evaluaciones consistentes
  maxTokens: 4000
})

// Opci√≥n 2: GPT-4 Turbo
const evaluatorGPT = new IAEvaluator({
  modelo: 'gpt-4-turbo',
  apiKey: Deno.env.get('OPENAI_API_KEY')!,
  temperatura: 0.3,
  maxTokens: 4000
})
```

### M√©todo `evaluar(prompt)`

```typescript
const resultado = await iaEvaluator.evaluar(prompt)

// Retorna: ResultadoIA
{
  contenido: string,        // Respuesta JSON de la IA
  tokens_utilizados: number,
  tiempo_ms: number,
  modelo: string,
  error?: string
}
```

### Modelos Soportados

- `claude-sonnet-4` ‚Üí Anthropic API
- `claude-opus-4` ‚Üí Anthropic API
- `gpt-4-turbo` ‚Üí OpenAI API
- `gpt-4o` ‚Üí OpenAI API

**Recomendaci√≥n:** `claude-sonnet-4` con `temperatura: 0.3` para evaluaciones m√°s consistentes.

---

## Edge Functions

Las Edge Functions ejecutan el an√°lisis en Deno runtime de Supabase.

### Estructura de una Edge Function

```typescript
// supabase/functions/analizar-modulo1-tarea1/index.ts

import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'
import { RubricasEngine } from '../_shared/rubricas-engine.ts'
import { IAEvaluator } from '../_shared/ia-evaluator.ts'
import { Logger } from '../_shared/logger.ts'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

serve(async (req) => {
  // 1. CORS preflight
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  const logger = new Logger('analizar-modulo1-tarea1')

  try {
    // 2. Obtener datos
    const { tarea_id } = await req.json()

    // 3. Autenticar y conectar a Supabase
    const supabaseUrl = Deno.env.get('SUPABASE_URL')
    const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')
    const supabase = createClient(supabaseUrl, supabaseKey)

    // 4. Cargar contexto de la tarea
    const { data: tarea } = await supabase
      .from('tareas_portafolio')
      .select(`
        *,
        modulo:modulos_portafolio!inner(
          *,
          portafolio:portafolios!inner(
            nivel_educativo,
            asignatura,
            a√±o_evaluacion
          )
        )
      `)
      .eq('id', tarea_id)
      .single()

    const portafolio = tarea.modulo.portafolio

    // 5. Inicializar motor de r√∫bricas
    const rubricasEngine = new RubricasEngine(supabase, 'analizar-m1-t1')

    // 6. Cargar r√∫bricas
    const rubricas = await rubricasEngine.cargarRubricas({
      a√±o: portafolio.a√±o_evaluacion,
      nivel_educativo: portafolio.nivel_educativo,
      asignatura: portafolio.asignatura,
      modulo: 1,
      tarea: 1,
    })

    // 7. Inicializar evaluador de IA
    const iaEvaluator = new IAEvaluator({
      modelo: 'claude-sonnet-4',
      apiKey: Deno.env.get('ANTHROPIC_API_KEY')!,
      temperatura: 0.3,
      maxTokens: 4000,
    })

    // 8. Evaluar cada indicador
    const evaluaciones = []

    for (const rubrica of rubricas) {
      logger.info(`Evaluando ${rubrica.indicador_id}...`)

      const evaluacion = await rubricasEngine.evaluarIndicador(
        rubrica,
        tarea.contenido_texto, // El texto a evaluar
        iaEvaluator
      )

      // 9. Guardar en BD
      await supabase
        .from('evaluaciones_indicador')
        .upsert({
          tarea_id,
          indicador_id: rubrica.indicador_id,
          rubrica_id: rubrica.id,
          nivel_alcanzado: evaluacion.nivel_alcanzado,
          puntaje: evaluacion.puntaje,
          condiciones_cumplidas: evaluacion.condiciones_cumplidas,
          condiciones_totales: evaluacion.condiciones_totales,
          condiciones_evaluadas: evaluacion.condiciones_evaluadas,
          justificacion: evaluacion.justificacion,
          para_siguiente_nivel: evaluacion.para_siguiente_nivel,
          evidencias_textuales: evaluacion.evidencias_destacadas,
          fortalezas: evaluacion.fortalezas,
          recomendaciones: evaluacion.recomendaciones,
          correccion_aplicada: evaluacion.correccion_aplicada,
          nota_correccion: evaluacion.nota_correccion,
          promedio_nacional: evaluacion.promedio_nacional,
          desviacion_estandar: evaluacion.desviacion_estandar,
          percentil: evaluacion.percentil,
        })

      evaluaciones.push(evaluacion)

      logger.info(`‚úÖ ${rubrica.indicador_id} evaluado: ${evaluacion.nivel_alcanzado} (${evaluacion.puntaje})`)
    }

    // 10. Retornar resultado
    return new Response(
      JSON.stringify({
        success: true,
        evaluaciones,
        puntaje_promedio: evaluaciones.reduce((sum, e) => sum + e.puntaje, 0) / evaluaciones.length,
      }),
      {
        status: 200,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    )
  } catch (error) {
    logger.error('Error en an√°lisis', error as Error)

    return new Response(
      JSON.stringify({
        success: false,
        error: error instanceof Error ? error.message : 'Error desconocido',
      }),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    )
  }
})
```

### Desplegar Edge Function

```bash
# 1. Configurar secretos en Supabase Dashboard
# Settings ‚Üí Edge Functions ‚Üí Secrets:
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...

# 2. Desplegar
supabase functions deploy analizar-modulo1-tarea1

# 3. Ver logs
supabase functions logs analizar-modulo1-tarea1
```

---

## Gu√≠a de Uso

### Setup Inicial

#### 1. Ejecutar migraci√≥n

```bash
# En Supabase SQL Editor
-- Ejecutar: sql/migrations/20250107_create_rubricas_mbe.sql
```

#### 2. Cargar datos de r√∫bricas

```bash
# En Supabase SQL Editor
-- Ejecutar: sql/seed/seed_rubricas_modulo1.sql

# O desde terminal (si tienes CLI configurado)
npm run seed:rubricas
```

#### 3. Configurar API Keys

En `.env.local` (Next.js):
```bash
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...
```

En Supabase Dashboard ‚Üí Edge Functions ‚Üí Secrets:
```
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...
```

### Usar desde Frontend

```typescript
// hooks/useAIAnalysis.ts (ya existe en ProfeFlow)
import { useCallback } from 'react'
import { createBrowserClient } from '@/lib/supabase/client'

export function useAIAnalysis() {
  const supabase = createBrowserClient()

  const analizarTarea = useCallback(async (tareaId: string) => {
    const { data: { session } } = await supabase.auth.getSession()

    if (!session) throw new Error('No autenticado')

    const response = await fetch(
      `${process.env.NEXT_PUBLIC_SUPABASE_URL}/functions/v1/analizar-modulo1-tarea1`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${session.access_token}`,
        },
        body: JSON.stringify({ tarea_id: tareaId }),
      }
    )

    if (!response.ok) {
      throw new Error('Error al analizar tarea')
    }

    return await response.json()
  }, [supabase])

  return { analizarTarea }
}

// Uso en componente
function MiComponente() {
  const { analizarTarea } = useAIAnalysis()

  const handleAnalizar = async () => {
    try {
      const resultado = await analizarTarea(tareaId)
      console.log('Evaluaciones:', resultado.evaluaciones)
      console.log('Puntaje promedio:', resultado.puntaje_promedio)
    } catch (error) {
      console.error(error)
    }
  }

  return <button onClick={handleAnalizar}>Analizar con IA</button>
}
```

---

## Agregar Nuevas R√∫bricas

### Paso 1: Preparar datos de la r√∫brica

Estructura completa en JSONB:

```json
{
  "destacado": {
    "nivel": "Destacado",
    "letra": "D",
    "puntaje": 4.0,
    "logica": "AND",
    "descripcion": "Descripci√≥n detallada del nivel destacado...",
    "condiciones": [
      {
        "id": "D_1",
        "descripcion": "Primera condici√≥n",
        "tipo": "calidad",
        "requiere_evidencia": true,
        "criterios": {
          "palabras_clave": ["palabra1", "palabra2"],
          "longitud_minima": 50,
          "elementos_requeridos": ["elemento1", "elemento2"]
        },
        "peso": 1.0
      }
    ],
    "notas": "Notas adicionales"
  },
  "competente": { ... },
  "basico": { ... },
  "insatisfactorio": { ... }
}
```

### Paso 2: Crear script de seed

```sql
-- sql/seed/seed_rubricas_modulo2.sql

INSERT INTO rubricas_mbe (
  indicador_id,
  nombre_indicador,
  descripcion_general,
  a√±o_vigencia,
  nivel_educativo,
  asignatura,
  modalidad,
  modulo,
  tarea,
  peso_porcentaje,
  niveles_desempeno,
  fuente_oficial,
  pagina_manual,
  notas_aclaratorias,
  ejemplos,
  activo,
  version
) VALUES (
  'M2_I1',
  'Nombre del indicador',
  'Descripci√≥n general...',
  2025,
  'general',
  NULL,
  'regular',
  2,
  1,
  20.00,
  '{...}'::jsonb,  -- ‚Üê JSON completo aqu√≠
  'Manual MBE 2025',
  25,
  'Notas aclaratorias...',
  ARRAY['Ejemplo 1', 'Ejemplo 2'],
  true,
  '1.0'
) ON CONFLICT (indicador_id, a√±o_vigencia, nivel_educativo, COALESCE(asignatura, ''))
DO UPDATE SET
  niveles_desempeno = EXCLUDED.niveles_desempeno,
  updated_at = NOW();
```

### Paso 3: Ejecutar seed

```bash
# En Supabase SQL Editor
-- Ejecutar el archivo seed

# Verificar inserci√≥n
SELECT indicador_id, nombre_indicador
FROM rubricas_mbe
WHERE indicador_id = 'M2_I1';
```

### Paso 4: Crear Edge Function espec√≠fica (opcional)

Si el m√≥dulo requiere l√≥gica especializada, crear nueva Edge Function:

```bash
# Copiar estructura base
cp -r supabase/functions/analizar-modulo1-tarea1 \
      supabase/functions/analizar-modulo2-tarea1

# Editar y adaptar l√≥gica espec√≠fica

# Desplegar
supabase functions deploy analizar-modulo2-tarea1
```

---

## Ejemplos Completos

### Ejemplo 1: Evaluar M√≥dulo 1, Tarea 1

```typescript
// Edge Function completo
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'
import { RubricasEngine } from '../_shared/rubricas-engine.ts'
import { IAEvaluator } from '../_shared/ia-evaluator.ts'

serve(async (req) => {
  const { tarea_id } = await req.json()

  const supabase = createClient(
    Deno.env.get('SUPABASE_URL')!,
    Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
  )

  // Cargar tarea con contexto
  const { data: tarea } = await supabase
    .from('tareas_portafolio')
    .select('*, modulo:modulos_portafolio!inner(*, portafolio:portafolios!inner(*))')
    .eq('id', tarea_id)
    .single()

  const portafolio = tarea.modulo.portafolio

  // Inicializar motor
  const engine = new RubricasEngine(supabase, 'eval-m1-t1')

  // Cargar r√∫bricas
  const rubricas = await engine.cargarRubricas({
    a√±o: portafolio.a√±o_evaluacion,
    nivel_educativo: portafolio.nivel_educativo,
    asignatura: portafolio.asignatura,
    modulo: 1,
    tarea: 1
  })

  // Inicializar IA
  const ia = new IAEvaluator({
    modelo: 'claude-sonnet-4',
    apiKey: Deno.env.get('ANTHROPIC_API_KEY')!,
    temperatura: 0.3,
    maxTokens: 4000
  })

  // Evaluar
  const evaluaciones = []
  for (const rubrica of rubricas) {
    const evaluacion = await engine.evaluarIndicador(
      rubrica,
      tarea.planificacion_texto,
      ia
    )

    // Guardar
    await supabase.from('evaluaciones_indicador').upsert({
      tarea_id,
      indicador_id: rubrica.indicador_id,
      ...evaluacion
    })

    evaluaciones.push(evaluacion)
  }

  return new Response(JSON.stringify({ success: true, evaluaciones }), {
    headers: { 'Content-Type': 'application/json' }
  })
})
```

### Ejemplo 2: Consultar evaluaciones desde Next.js

```typescript
// app/api/portafolio/evaluaciones/route.ts
import { createClient } from '@/lib/supabase/server'
import { NextResponse } from 'next/server'

export async function GET(req: Request) {
  const { searchParams } = new URL(req.url)
  const tareaId = searchParams.get('tarea_id')

  const supabase = createClient()

  const { data, error } = await supabase
    .from('evaluaciones_indicador')
    .select('*')
    .eq('tarea_id', tareaId)
    .order('indicador_id')

  if (error) {
    return NextResponse.json({ error: error.message }, { status: 500 })
  }

  return NextResponse.json({ evaluaciones: data })
}
```

### Ejemplo 3: Mostrar evaluaciones en UI

```typescript
// components/portafolio/ResultadosEvaluacion.tsx
'use client'

import { useEffect, useState } from 'react'
import { Badge } from '@/components/ui/Badge'
import { Card } from '@/components/ui/Card'

interface Evaluacion {
  indicador_id: string
  nivel_alcanzado: string
  puntaje: number
  justificacion: string
  fortalezas: string[]
  recomendaciones: Array<{
    prioridad: string
    accion: string
    impacto: string
  }>
  percentil?: number
}

export function ResultadosEvaluacion({ tareaId }: { tareaId: string }) {
  const [evaluaciones, setEvaluaciones] = useState<Evaluacion[]>([])
  const [loading, setLoading] = useState(true)

  useEffect(() => {
    fetch(`/api/portafolio/evaluaciones?tarea_id=${tareaId}`)
      .then(res => res.json())
      .then(data => {
        setEvaluaciones(data.evaluaciones)
        setLoading(false)
      })
  }, [tareaId])

  if (loading) return <div>Cargando evaluaciones...</div>

  const promedioGeneral = evaluaciones.reduce((sum, e) => sum + e.puntaje, 0) / evaluaciones.length

  return (
    <div className="space-y-6">
      <Card className="p-6">
        <h2 className="text-2xl font-bold mb-2">Resumen General</h2>
        <div className="text-4xl font-bold text-blue-600">{promedioGeneral.toFixed(2)}</div>
        <p className="text-gray-600">Puntaje promedio</p>
      </Card>

      {evaluaciones.map((evaluacion) => (
        <Card key={evaluacion.indicador_id} className="p-6">
          <div className="flex items-start justify-between mb-4">
            <div>
              <h3 className="font-semibold text-lg">{evaluacion.indicador_id}</h3>
              <Badge variant={getBadgeVariant(evaluacion.nivel_alcanzado)}>
                {evaluacion.nivel_alcanzado} - {evaluacion.puntaje}
              </Badge>
              {evaluacion.percentil && (
                <span className="ml-2 text-sm text-gray-600">
                  Percentil {evaluacion.percentil}
                </span>
              )}
            </div>
          </div>

          <p className="text-gray-700 mb-4">{evaluacion.justificacion}</p>

          {evaluacion.fortalezas.length > 0 && (
            <div className="mb-4">
              <h4 className="font-semibold text-green-700 mb-2">‚úÖ Fortalezas</h4>
              <ul className="list-disc list-inside space-y-1">
                {evaluacion.fortalezas.map((f, i) => (
                  <li key={i} className="text-sm">{f}</li>
                ))}
              </ul>
            </div>
          )}

          {evaluacion.recomendaciones.length > 0 && (
            <div>
              <h4 className="font-semibold text-orange-700 mb-2">üí° Recomendaciones</h4>
              <div className="space-y-2">
                {evaluacion.recomendaciones.map((rec, i) => (
                  <div key={i} className="border-l-4 border-orange-400 pl-3 py-1">
                    <div className="flex items-center gap-2">
                      <Badge variant={rec.prioridad === 'alta' ? 'danger' : 'warning'}>
                        {rec.prioridad}
                      </Badge>
                      <span className="font-medium text-sm">{rec.accion}</span>
                    </div>
                    <p className="text-xs text-gray-600 mt-1">{rec.impacto}</p>
                  </div>
                ))}
              </div>
            </div>
          )}
        </Card>
      ))}
    </div>
  )
}

function getBadgeVariant(nivel: string) {
  switch (nivel) {
    case 'Destacado': return 'success'
    case 'Competente': return 'default'
    case 'B√°sico': return 'warning'
    case 'Insatisfactorio': return 'danger'
    default: return 'default'
  }
}
```

---

## Troubleshooting

### Problema: "No se encontraron r√∫bricas para el contexto especificado"

**Causa:** Filtros demasiado estrictos o datos no cargados.

**Soluci√≥n:**
```sql
-- Verificar r√∫bricas disponibles
SELECT indicador_id, nivel_educativo, asignatura, modulo, tarea, activo
FROM rubricas_mbe
WHERE a√±o_vigencia = 2025
ORDER BY modulo, tarea;

-- Si est√°n inactivas, activar
UPDATE rubricas_mbe
SET activo = TRUE
WHERE indicador_id = 'M1_I1';
```

### Problema: "Error cargando r√∫bricas: column 'rubricas_mbe.activo' does not exist"

**Causa:** Migraci√≥n no ejecutada.

**Soluci√≥n:**
```bash
# Ejecutar migraci√≥n en Supabase SQL Editor
-- sql/migrations/20250107_create_rubricas_mbe.sql
```

### Problema: IA retorna nivel incorrecto constantemente

**Causa:** Prompt ambiguo o temperatura muy alta.

**Soluci√≥n:**
```typescript
// Reducir temperatura
const ia = new IAEvaluator({
  modelo: 'claude-sonnet-4',
  apiKey: '...',
  temperatura: 0.2,  // ‚Üê M√°s determin√≠stico
  maxTokens: 4000
})

// El sistema verificar√° la l√≥gica y corregir√° autom√°ticamente
// Revisar: evaluacion.correccion_aplicada === true
```

### Problema: "Anthropic API key not found"

**Causa:** Variable de entorno no configurada en Edge Functions.

**Soluci√≥n:**
```bash
# En Supabase Dashboard:
# Settings ‚Üí Edge Functions ‚Üí Secrets
# Agregar: ANTHROPIC_API_KEY=sk-ant-...

# Verificar en funci√≥n:
console.log('API Key exists:', !!Deno.env.get('ANTHROPIC_API_KEY'))
```

### Problema: Evaluaciones muy lentas

**Causa:** Llamadas secuenciales a IA.

**Soluci√≥n:** Paralelizar evaluaciones:
```typescript
// ‚ùå Lento (secuencial)
for (const rubrica of rubricas) {
  const evaluacion = await engine.evaluarIndicador(...)
}

// ‚úÖ R√°pido (paralelo)
const promesas = rubricas.map(rubrica =>
  engine.evaluarIndicador(rubrica, contenido, ia)
)
const evaluaciones = await Promise.all(promesas)
```

### Problema: JSON parsing error en respuesta de IA

**Causa:** IA retorn√≥ texto con markdown.

**Soluci√≥n:** El `parsearRespuesta()` ya limpia markdown autom√°ticamente:
```typescript
// Limpia:
// ```json\n{ ... }\n```
// { ... } // comentario
// Y extrae solo el JSON v√°lido
```

Si persiste, revisar logs:
```bash
supabase functions logs analizar-modulo1-tarea1 --tail
```

---

## Conclusi√≥n

El Sistema de R√∫bricas MBE 2025 est√° completamente implementado y listo para evaluar portafolios docentes con precisi√≥n y consistencia.

### Checklist de Implementaci√≥n

- ‚úÖ Migraci√≥n SQL ejecutada
- ‚úÖ Tipos TypeScript definidos
- ‚úÖ RubricasEngine implementado
- ‚úÖ IAEvaluator configurado
- ‚úÖ Edge Functions desplegadas
- ‚úÖ R√∫bricas M1 cargadas
- ‚úÖ Sistema de logging
- ‚úÖ Verificaci√≥n autom√°tica de l√≥gica
- ‚úÖ Estad√≠sticas comparativas
- ‚úÖ Documentaci√≥n completa

### Pr√≥ximos Pasos

1. **Cargar r√∫bricas de M√≥dulos 2 y 3**
2. **Crear Edge Functions espec√≠ficas por m√≥dulo/tarea**
3. **Implementar dashboard de resultados en UI**
4. **Configurar alertas de errores**
5. **Optimizar costos de IA** (cacheo de prompts, batch processing)

---

**Documentaci√≥n generada:** 2025-01-07
**Versi√≥n:** 1.0
**Autor:** ProfeFlow Team
