# üìä Exportaci√≥n de M√©tricas JSON - Pipeline RAG

## üìã Resumen Ejecutivo

‚úÖ **Archivos Modificados**:
- `scripts/pipeline-document-mineduc/fase2_transform_multiproveedor.py` ‚Üí `transform_metrics.json`
- `scripts/pipeline-document-mineduc/fase3_load.py` ‚Üí `load_metrics.json`  
- `scripts/pipeline-document-mineduc/fase4_validacion_calidad.py` ‚Üí `validation_metrics.json`
- `scripts/pipeline-document-mineduc/fase5_optimize.py` ‚Üí `optimize_metrics.json`
- (fase6 ya inclu√≠a `metrics_report.json` originalmente)

‚úÖ **Workflow Actualizado**: `.github/workflows/pipeline-documentos-mineduc.yml`
- JSON-first extraction con `jq`
- Fallback autom√°tico a `grep`
- 7 artifacts persistentes (7-90 d√≠as retention)
- Resumen consolidado con tabla Markdown

‚úÖ **Beneficios**:
- M√©tricas estructuradas para an√°lisis hist√≥rico
- Integraci√≥n con dashboards externos (Grafana, Kibana)
- Debugging facilitado (logs + JSON en mismo artifact)
- Compatibilidad backward (scripts mantienen output consola)

---

## Implementaci√≥n Completada

Se ha agregado funcionalidad de exportaci√≥n de m√©tricas en formato JSON a todas las fases del pipeline ETL RAG.

---

## ‚úÖ Scripts Modificados

### 1. **fase2_transform_multiproveedor.py**

#### Archivo JSON Generado: `transform_metrics.json`

```json
{
  "timestamp": "2025-11-08T22:13:45.123456",
  "fase": "transform",
  "documentos_procesados": 10,
  "transformados": 9,
  "fallidos": 1,
  "tasa_exito": 90.0,
  "tiempo_total_segundos": 45.32,
  "tiempo_promedio_por_doc": 5.03,
  "speedup_paralelismo": 3.2,
  "costo_ia": {
    "total_usd": 0.0234,
    "promedio_por_doc_usd": 0.0026
  },
  "proveedores_usados": {
    "gemini": {
      "count": 5,
      "porcentaje": 55.6
    },
    "gpt-4o": {
      "count": 3,
      "porcentaje": 33.3
    },
    "cache": {
      "count": 1,
      "porcentaje": 11.1
    }
  },
  "cache_stats": {
    "cache_hits": 1,
    "cache_miss": 8
  }
}
```

#### Funci√≥n Agregada:
```python
def export_metrics_json(metrics: dict, filepath: str):
    """Exporta m√©tricas en formato JSON para GitHub Actions"""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=2, ensure_ascii=False)
        print(f"\nüìÑ M√©tricas exportadas: {filepath}")
    except Exception as e:
        print(f"\n‚ö†Ô∏è Error exportando m√©tricas: {e}")
```

---

### 2. **fase3_load.py**

#### Archivo JSON Generado: `load_metrics.json`

```json
{
  "timestamp": "2025-11-08T22:14:05.654321",
  "fase": "load",
  "documentos_procesados": 9,
  "documentos_cargados": 9,
  "documentos_fallidos": 0,
  "tasa_exito": 100.0,
  "chunks": {
    "total_generados": 145,
    "promedio_por_documento": 16
  },
  "embeddings": {
    "modelo": "text-embedding-3-large",
    "dimensiones": 1536,
    "tokens_totales": 87450,
    "tokens_promedio_por_doc": 9716
  },
  "costos": {
    "total_usd": 0.0114,
    "promedio_por_documento_usd": 0.0013,
    "costo_por_1k_tokens_usd": 0.00013
  },
  "configuracion": {
    "max_chunk_size": 6000,
    "min_chunk_size": 500,
    "overlap_size": 200
  }
}
```

#### Funci√≥n Agregada

```python
def export_metrics_json(metrics: dict, filepath: str):
    """Exporta m√©tricas en formato JSON para GitHub Actions"""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=2, ensure_ascii=False)
        print(f"\nüìÑ M√©tricas exportadas: {filepath}")
    except Exception as e:
        print(f"\n‚ö†Ô∏è Error exportando m√©tricas: {e}")
```

#### Modificaciones
- Importado `json` en headers
- Agregada funci√≥n `export_metrics_json()` antes del `sys.exit()`
- Incluye configuraci√≥n de chunking y embeddings
- Calcula costo por 1K tokens para referencia

---

### 3. **fase4_validacion_calidad.py**

#### Archivo JSON Generado: `validation_metrics.json`

```json
{
  "timestamp": "2025-11-08T22:14:12.987654",
  "fase": "validacion",
  "total_documentos": 9,
  "aprobados": 8,
  "rechazados": 1,
  "calidad_promedio": 0.8523,
  "total_chunks": 145,
  "chunks_sin_embedding": 2,
  "tasa_aprobacion": 88.89,
  "detalles_rechazados": [
    {
      "id": "doc_123",
      "titulo": "Documento con problemas",
      "calidad": 0.45,
      "chunks": {
        "total": 5,
        "sin_embedding": 2
      }
    }
  ]
}
```

#### Modificaciones:
- Agregada funci√≥n `export_metrics_json()` en el bloque `if __name__ == '__main__'`
- Exporta m√©tricas antes del `sys.exit()`
- Incluye detalles de documentos rechazados

---

### 3. **fase5_optimize.py**

#### Archivo JSON Generado: `optimize_metrics.json`

```json
{
  "timestamp": "2025-11-08T22:15:30.456789",
  "fase": "optimize",
  "salud_sistema": true,
  "indices_verificados": true,
  "optimizacion_exitosa": true,
  "estadisticas_actualizadas": true,
  "metricas": {
    "documentos_completados": 9,
    "chunks_con_embedding": 145,
    "ratio_chunks_doc": 16.1,
    "embeddings_en_cache": 120,
    "tamano_indice_estimado_mb": 1.1
  },
  "recomendacion_reindexar": false
}
```

#### Modificaciones:
- Exporta m√©tricas al final de `main()` antes del `return`
- Incluye `import json` dentro de la funci√≥n para evitar dependencia global
- Captura estado de salud del sistema y m√©tricas de √≠ndices

---

### 4. **fase6_metrics.py**

‚úÖ **Ya inclu√≠a exportaci√≥n JSON** mediante el argumento `--export-json`

Archivo generado: `metrics_report.json` (como se defini√≥ previamente)

---

## üîß GitHub Actions Workflow

El workflow ya est√° configurado para:

### Lectura de M√©tricas JSON

```yaml
- name: Ejecutar transformaci√≥n
  id: transform
  run: |
    python scripts/pipeline-document-mineduc/fase2_transform_multiproveedor.py 2>&1 | tee transform.log
    
    # Leer de JSON (prioritario)
    if [ -f transform_metrics.json ]; then
      transformed=$(jq -r '.transformados' transform_metrics.json)
      cost=$(jq -r '.costo_ia.total_usd' transform_metrics.json)
      success="true"
    else
      # Fallback a grep
      transformed=$(grep -oP "Transformados: \K[0-9]+" transform.log || echo "0")
      cost=$(grep -oP "Costo total IA: \\$\K[0-9.]+" transform.log || echo "0")
      success="false"
    fi
    
    echo "count=$transformed" >> $GITHUB_OUTPUT
    echo "cost=$cost" >> $GITHUB_OUTPUT
```

### Upload de Artefactos

```yaml
- name: Upload transform metrics
  if: always()
  uses: actions/upload-artifact@v4
  with:
    name: transform-metrics
    path: |
      transform.log
      transform_metrics.json
    if-no-files-found: ignore
    retention-days: 30
```

---

## üìÅ Artefactos Generados por Fase

| Fase | Archivo JSON | Retenci√≥n | Contenido Clave |
|------|--------------|-----------|-----------------|
| **1. Extract** | `monitor_response.json` | 7 d√≠as | Documentos nuevos/actualizados |
| **2. Transform** | `transform_metrics.json` | 30 d√≠as | Transformados, costo IA, proveedores |
| **3. Load** | `load_metrics.json` | 30 d√≠as | Chunks, tokens, embeddings, costo |
| **4. Validaci√≥n** | `validation_metrics.json` | 30 d√≠as | Calidad, aprobados/rechazados |
| **5. Optimizaci√≥n** | `optimize_metrics.json` | 30 d√≠as | √çndices, salud sistema |
| **6. M√©tricas** | `metrics_report.json` | 90 d√≠as | Consolidado + hist√≥rico |

---

## üéØ Beneficios

### 1. **Robustez**
- ‚úÖ Fallback autom√°tico a `grep` si JSON no existe
- ‚úÖ Validaci√≥n de campos con `jq`
- ‚úÖ Manejo de errores en exportaci√≥n

### 2. **Trazabilidad**
- ‚úÖ Timestamp en cada m√©trica
- ‚úÖ Artefactos persistentes (7-90 d√≠as)
- ‚úÖ Hist√≥rico completo por workflow run

### 3. **Integraci√≥n**
- ‚úÖ Compatible con dashboards externos (Grafana, Kibana)
- ‚úÖ API-friendly (JSON est√°ndar)
- ‚úÖ F√°cil parsing con `jq` o Python

### 4. **Debugging**
- ‚úÖ Logs + JSON en mismo artefacto
- ‚úÖ Detalles de documentos rechazados
- ‚úÖ M√©tricas de proveedores IA usados

---

## üöÄ Uso

### Descarga Manual de M√©tricas

```bash
# Desde workflow run
gh run download <run-id> -n transform-metrics

# Ver m√©tricas
cat transform_metrics.json | jq '.'

# Extraer costo espec√≠fico
cat transform_metrics.json | jq -r '.costo_ia.total_usd'
```

### An√°lisis Program√°tico

```python
import json

# Cargar m√©tricas
with open('transform_metrics.json') as f:
    metrics = json.load(f)

# An√°lisis
print(f"Tasa de √©xito: {metrics['tasa_exito']}%")
print(f"Proveedor m√°s usado: {max(metrics['proveedores_usados'].items(), key=lambda x: x[1]['count'])[0]}")
print(f"Ahorro por cach√©: ${metrics['cache_stats']['cache_hits'] * 0.003:.4f}")
```

---

## ‚ö†Ô∏è Notas Importantes

### Compatibilidad Backward

Los scripts mantienen compatibilidad con ejecuciones previas:
- ‚úÖ Si falla exportaci√≥n JSON ‚Üí solo warning, no error fatal
- ‚úÖ Workflow tiene fallback a `grep` de logs
- ‚úÖ JSON es adicional, no reemplaza logs existentes

### Formato JSON Est√°ndar

Todos los archivos usan:
- Encoding UTF-8
- `indent=2` para legibilidad
- `ensure_ascii=False` para caracteres especiales
- Campos consistentes: `timestamp`, `fase`, etc.

### Ubicaci√≥n de Archivos

Los archivos JSON se generan en el **directorio de trabajo actual** donde se ejecuta el script:
- En GitHub Actions: Directorio ra√≠z del repo
- Local: Donde ejecutes `python scripts/...`

---

## üìä Dashboard Recomendado

Con estos JSONs puedes crear dashboard que muestre:

1. **Tendencia de costos** (por fecha)
2. **Distribuci√≥n de proveedores IA**
3. **Tasa de √©xito por fase**
4. **Velocidad de procesamiento** (docs/hora)
5. **Efectividad de cach√©** (% hits)
6. **Calidad promedio de documentos**

---

**Implementado por**: GitHub Copilot  
**Fecha**: 2025-11-08  
**Versi√≥n**: v2.1 (JSON Export)
