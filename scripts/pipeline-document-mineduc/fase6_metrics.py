#!/usr/bin/env python3
"""
Script para registrar m√©tricas del pipeline de procesamiento de documentos MINEDUC.

Este script corresponde a la FASE 6 del pipeline ETL y se encarga de registrar
las m√©tricas de procesamiento en las tablas de Supabase correspondientes.

Funcionalidades:
- Registra m√©tricas generales de procesamiento en 'metricas_procesamiento'
- Registra m√©tricas espec√≠ficas del pipeline RAG en 'metricas_pipeline_rag'
- Maneja errores de inserci√≥n de forma graceful
- Acepta par√°metros de l√≠nea de comandos para las m√©tricas

Argumentos de l√≠nea de comandos:
    --downloaded (int): N√∫mero de documentos descargados (default: 0)
    --transformed (int): N√∫mero de documentos transformados (default: 0)
    --loaded (int): N√∫mero de documentos cargados exitosamente (default: 0)
    --validated (int): N√∫mero de chunks validados (default: 0)
    --quality (float): Puntuaci√≥n de calidad de los documentos (default: 0.0)
    --tokens (int): N√∫mero total de tokens procesados (default: 0)
    --cost (float): Costo total del procesamiento en USD (default: 0.0)
    --workflow-id (str): ID del workflow de GitHub Actions (requerido)

Variables de entorno requeridas:
    SUPABASE_URL: URL del proyecto Supabase
    SUPABASE_SERVICE_ROLE_KEY: Clave de servicio de Supabase

Salida:
    - C√≥digo de salida 0 si todo es exitoso
    - Mensajes de estado en stdout indicando el progreso
    - Mensajes de error para inserciones fallidas

Ejemplo de uso:
    python fase6_metrics.py --downloaded 100 --transformed 95 --loaded 90 
                           --validated 450 --quality 0.85 --tokens 50000 
                           --cost 2.50 --workflow-id "12345678"
"""
"""FASE 6: Registrar m√©tricas del pipeline"""
import os, sys, argparse
from datetime import date, datetime
from dotenv import load_dotenv
from supabase import create_client

load_dotenv('.env.local')
supabase = create_client(os.getenv('SUPABASE_URL'), os.getenv('SUPABASE_SERVICE_ROLE_KEY'))

parser = argparse.ArgumentParser()
parser.add_argument('--downloaded', type=int, default=0)
parser.add_argument('--transformed', type=int, default=0)
parser.add_argument('--loaded', type=int, default=0)
parser.add_argument('--validated', type=int, default=0)
parser.add_argument('--quality', type=float, default=0.0)
parser.add_argument('--tokens', type=int, default=0)
parser.add_argument('--cost', type=float, default=0.0)
parser.add_argument('--workflow-id', type=str, required=True)
args = parser.parse_args()

print("üìä Registrando m√©tricas...")

# Tabla metricas_procesamiento
try:
    supabase.table('metricas_procesamiento').insert({
        'tipo': 'etl_documentos',
        'documentos_procesados': args.loaded,
        'documentos_fallidos': args.downloaded - args.loaded,
        'tiempo_total_ms': 0,
        'metadata': {
            'downloaded': args.downloaded,
            'transformed': args.transformed,
            'validated': args.validated,
            'quality': args.quality,
            'tokens': args.tokens,
            'cost_usd': args.cost
        }
    }).execute()
    print("‚úÖ metricas_procesamiento")
except Exception as e:
    print(f"‚ö†Ô∏è metricas_procesamiento: {e}")

# Tabla metricas_pipeline_rag
try:
    supabase.table('metricas_pipeline_rag').insert({
        'fecha': date.today().isoformat(),
        'documentos_monitoreados': args.downloaded,
        'documentos_procesados': args.loaded,
        'chunks_validados': args.validated,
        'errores_criticos': 0,
        'latencia_procesamiento_ms': 0,
        'workflow_run_id': args.workflow_id
    }).execute()
    print("‚úÖ metricas_pipeline_rag")
except Exception as e:
    print(f"‚ö†Ô∏è metricas_pipeline_rag: {e}")

print("‚úÖ M√©tricas registradas")
sys.exit(0)
