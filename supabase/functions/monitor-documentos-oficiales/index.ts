// supabase/functions/monitor-documentos-oficiales/index.ts

import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { DocumentProcessor } from '../shared/document-processor.ts'
import { AIAnalyzer } from '../shared/ai-analyzer.ts'
import { crearClienteServicio, UnauthorizedError } from '../shared/service-auth.ts'
import { PDFExtractor, type PDFMetadata } from '../shared/pdf-extractor.ts'

// ============================================
// CONFIGURACI√ìN
// ============================================

const CONFIG = {
  // Rate limiting - OPTIMIZADO para velocidad
  DELAY_BETWEEN_CATEGORIES: 200, // Reducido de 500ms a 200ms
  DELAY_BETWEEN_DOCUMENTS: 50,   // Reducido de 100ms a 50ms
  MAX_RETRIES: 2, // Reducido de 3 a 2 reintentos
  RETRY_DELAY_BASE: 500, // Reducido de 1000ms a 500ms

  // Procesamiento
  MAX_CONCURRENT_DOWNLOADS: 8, // Aumentado para procesamiento m√°s r√°pido
  MAX_DOCS_PER_EXECUTION: 10, // REDUCIDO a 10 para evitar timeouts (era 20)
  PDF_SAMPLE_PAGES: 2, // Solo 2 p√°ginas para clasificaci√≥n IA (reducido)
  PDF_DOWNLOAD_TIMEOUT: 10000, // Reducido a 10s timeout (era 15s)
  ENABLE_AI_CLASSIFICATION: false, // ‚ö†Ô∏è DESHABILITADO para acelerar scraping

  // Thresholds
  MIN_AI_CONFIDENCE: 0.70, // Confianza m√≠nima para clasificaci√≥n IA
  MIN_PDF_SIZE: 10 * 1024, // 10KB m√≠nimo
  MAX_PDF_SIZE: 100 * 1024 * 1024, // 100MB m√°ximo
  PDF_SAMPLE_SIZE: 200000, // Reducido a 200KB (era 500KB)
}

// URLs oficiales del MINEDUC con subcategor√≠as
const URLS_OFICIALES = {
  manuales: {
    url: 'https://www.docentemas.cl/documentos-descargables/manuales-de-instrumentos/',
    subcategorias: ['Manuales de Instrumentos']
  },
  basesCurriculares: {
    url: 'https://www.docentemas.cl/documentos-descargables/documentos-curriculares/',
    subcategorias: [
      'Bases curriculares',
      'Priorizaci√≥n Curricular',
      'Programas EMTP',
      'Marco para la Buena Ense√±anza'
    ]
  },
  rubricasPortafolio: {
    url: 'https://www.docentemas.cl/documentos-descargables/rubricas',
    subcategorias: ['R√∫bricas Portafolio'] // R√∫bricas de evaluaci√≥n docente
  },
  tiposDeInformesDeResultados: {
    url: 'https://www.docentemas.cl/documentos-descargables/tipos-de-informes-de-resultados',
    subcategorias: ['Informes de Resultados']
  },
  documentosLegales: {
    url: 'https://www.docentemas.cl/documentos-descargables/documentos-legales-2',
    subcategorias: ['Documentos Legales']
  }
}

export const PROCESAR_DOCUMENTO_FUNCTION = 'procesar-documentos'

// ============================================
// TIPOS E INTERFACES
// ============================================

interface DocumentoDetectado {
  nombre: string
  url: string
  tipo: string
  subcategoria: string
  a√±o: number
  nivel_educativo: string
  modalidad: string
  asignatura?: string
  hash?: string
  confianza_clasificacion?: number
}

interface ClasificacionMetadata {
  a√±o: number
  nivel: string
  modalidad: string
  asignatura?: string
  confianza: number
}

interface DocumentoActualizado extends DocumentoDetectado {
  id_existente: string
  version_anterior: string
  hash_nuevo: string
  cambios_detectados?: any
}

interface AnalisisDocumentos {
  nuevos: DocumentoDetectado[]
  actualizados: DocumentoActualizado[]
  duplicados: DocumentoDetectado[]
  invalidos: Array<{ doc: DocumentoDetectado; error: string }>
}

interface ResultadoProcesamiento {
  documento: string
  exito: boolean
  documento_id?: string
  duplicado?: boolean
  actualizado?: boolean
  error?: string
}

interface Reporte {
  fecha_monitoreo: string
  documentos_detectados: number
  documentos_nuevos: number
  documentos_nuevos_procesados: number
  documentos_nuevos_pendientes: number
  documentos_actualizados: number
  documentos_actualizados_procesados: number
  documentos_actualizados_pendientes: number
  documentos_duplicados: number
  documentos_invalidos: number
  procesamiento_exitoso: number
  procesamiento_fallido: number
  tiempo_total_ms: number
  pipeline_pendientes_descarga: number
  pipeline_descargados: number
  pipeline_total: number
  detalles: ResultadoProcesamiento[]
}

// ============================================
// UTILIDADES
// ============================================

/**
 * Ejecuta una funci√≥n con retry y exponential backoff
 */
async function retryWithBackoff<T>(
  fn: () => Promise<T>,
  maxRetries: number = CONFIG.MAX_RETRIES,
  baseDelay: number = CONFIG.RETRY_DELAY_BASE,
  context: string = 'operaci√≥n'
): Promise<T | null> {
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      return await fn()
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Error desconocido'
      const isLastAttempt = attempt === maxRetries - 1
      
      if (isLastAttempt) {
        console.log(`      ‚ùå ${context} fall√≥ despu√©s de ${maxRetries} intentos`)
        return null
      }
      
      const delay = baseDelay * Math.pow(2, attempt)
      console.log(`      ‚ö†Ô∏è  ${context} fall√≥ (intento ${attempt + 1}/${maxRetries}), reintentando en ${delay}ms...`)
      console.log(`         Error: ${errorMessage}`)
      
      await new Promise(resolve => setTimeout(resolve, delay))
    }
  }
  
  return null
}

export async function handler(req: Request): Promise<Response> {
  const startTime = Date.now()
  
  try {
    console.log('üîç Iniciando monitoreo documentos MINEDUC...')
    
    const supabase = crearClienteServicio(req)
    const processor = new DocumentProcessor(supabase)
    const aiAnalyzer = new AIAnalyzer()
    const pdfExtractor = new PDFExtractor()
    
    // Validar request
    const { force = false, skipScraping = false } = await req.json().catch(() => ({ force: false, skipScraping: false }))
    
    let documentosDetectados: DocumentoDetectado[] = []
    let analisisDocumentos: AnalisisDocumentos = {
      nuevos: [],
      actualizados: [],
      duplicados: [],
      invalidos: []
    }
    
    // OPTIMIZACI√ìN: Solo scrapear si force=true o si no hay documentos en BD
    const { count: totalDocumentos } = await supabase
      .from('documentos_oficiales')
      .select('*', { count: 'exact', head: true })
    
    const { count: pendientesCount } = await supabase
      .from('documentos_oficiales')
      .select('*', { count: 'exact', head: true })
      .eq('etapa_actual', 'pendiente_descarga')
    
    // Solo scrapear si: force=true, o (skipScraping=false Y no hay docs en BD)
    const debeScrapear = force || (!skipScraping && (totalDocumentos === 0))
    
    if (debeScrapear) {
      console.log('üì° Ejecutando scraping de sitio web...')
      // 1. SCRAPING con rate limiting
      documentosDetectados = await scrapearDocumentos(processor, aiAnalyzer, pdfExtractor)
      
      console.log(`\nüìã Total detectados: ${documentosDetectados.length} documentos`)
      
      // 2. COMPARACI√ìN con BD (detecci√≥n de duplicados mejorada)
      analisisDocumentos = await analizarDocumentos(
        supabase, 
        documentosDetectados,
        pdfExtractor,
        aiAnalyzer
      )
      
      console.log(`\nüìä An√°lisis completado:`)
      console.log(`  üÜï Nuevos: ${analisisDocumentos.nuevos.length}`)
      console.log(`  üîÑ Actualizados: ${analisisDocumentos.actualizados.length}`)
      console.log(`  ‚è≠Ô∏è  Duplicados: ${analisisDocumentos.duplicados.length}`)
      console.log(`  ‚ùå Inv√°lidos: ${analisisDocumentos.invalidos.length}`)
      
      // 3. REGISTRO R√ÅPIDO: Insertar documentos nuevos en BD sin descargar
      console.log(`\nüìù Registrando documentos nuevos en BD...`)
      const documentosRegistrados = await registrarDocumentosNuevos(
        supabase,
        analisisDocumentos.nuevos
      )
      
      console.log(`  ‚úÖ ${documentosRegistrados.length} documentos registrados con etapa 'pendiente_descarga'`)
    } else {
      console.log(`‚è≠Ô∏è  Saltando scraping - Total en BD: ${totalDocumentos}, Pendientes: ${pendientesCount}`)
    }
    
    // 4. PROCESAMIENTO: Descargar y procesar documentos pendientes (l√≠mite: MAX_DOCS_PER_EXECUTION)
    // Primero obtener estad√≠sticas totales
    const { count: totalPendientes } = await supabase
      .from('documentos_oficiales')
      .select('*', { count: 'exact', head: true })
      .eq('etapa_actual', 'pendiente_descarga')
    
    const { count: totalDescargados } = await supabase
      .from('documentos_oficiales')
      .select('*', { count: 'exact', head: true })
      .in('etapa_actual', ['descargado', 'transformando', 'transformado', 'transformado_errores'])
    
    console.log(`\nüìä Estado del pipeline:`)
    console.log(`   ‚è≥ Pendientes descarga: ${totalPendientes || 0}`)
    console.log(`   ‚úÖ Descargados: ${totalDescargados || 0}`)
    
    // Obtener lote para procesar
    const { data: documentosPendientes } = await supabase
      .from('documentos_oficiales')
      .select('*')
      .eq('etapa_actual', 'pendiente_descarga')
      .limit(CONFIG.MAX_DOCS_PER_EXECUTION)
    
    console.log(`\nüì• Descargando lote actual (${documentosPendientes?.length || 0} documentos)...`)
    
    let resultadosProcesamiento: ResultadoProcesamiento[] = []
    
    if (documentosPendientes && documentosPendientes.length > 0) {
      resultadosProcesamiento = await procesarDocumentosPendientes(
        supabase,
        documentosPendientes,
        processor
      )
    }
    
    // 5. REPORTE final
    const reporte = {
      fecha_monitoreo: new Date().toISOString(),
      documentos_detectados: documentosDetectados.length,
      documentos_nuevos: analisisDocumentos.nuevos.length,
      documentos_actualizados: analisisDocumentos.actualizados.length,
      documentos_duplicados: analisisDocumentos.duplicados.length,
      procesamiento_exitoso: resultadosProcesamiento.filter(r => r.exito).length,
      procesamiento_fallido: resultadosProcesamiento.filter(r => !r.exito).length,
      pipeline_pendientes_descarga: totalPendientes || 0,
      pipeline_descargados: totalDescargados || 0,
      pipeline_total: (totalPendientes || 0) + (totalDescargados || 0),
      tiempo_total_ms: Date.now() - startTime,
      detalles: resultadosProcesamiento
    }
    
    console.log('\n‚úÖ Monitoreo completado')
    console.log(`  üìä Nuevos: ${analisisDocumentos.nuevos.length}`)
    console.log(`  üîÑ Actualizados: ${analisisDocumentos.actualizados.length}`)
    console.log(`  ‚è≠Ô∏è  Duplicados (saltados): ${analisisDocumentos.duplicados.length}`)
    
    // 6. Notificar a administradores si hay cambios
    if (analisisDocumentos.nuevos.length > 0 || analisisDocumentos.actualizados.length > 0) {
      await notificarAdministradores(supabase, reporte)
    }

    return new Response(
      JSON.stringify({
        success: true,
        reporte
      }),
      {
        status: 200,
        headers: { 'Content-Type': 'application/json' }
      }
    )
    
  } catch (error) {
    if (error instanceof UnauthorizedError) {
      return new Response(
        JSON.stringify({ error: 'No autorizado' }),
        {
          status: 401,
          headers: { 'Content-Type': 'application/json' }
        }
      )
    }

    console.error('‚ùå Error en monitoreo:', error)
    
    const errorMessage = error instanceof Error ? error.message : 'Error desconocido'

    return new Response(
      JSON.stringify({
        error: 'Error en monitoreo de documentos',
        details: errorMessage
      }),
      {
        status: 500,
        headers: { 'Content-Type': 'application/json' }
      }
    )
  }
}

if (import.meta.main) {
  serve(handler)
}

// ============================================
// FUNCIONES PRINCIPALES
// ============================================

/**
 * Scrapea documentos del sitio DocenteM√°s con rate limiting
 */
async function scrapearDocumentos(
  processor: DocumentProcessor,
  aiAnalyzer: AIAnalyzer,
  pdfExtractor: PDFExtractor
): Promise<DocumentoDetectado[]> {

  const documentosDetectados: DocumentoDetectado[] = []

  for (const [tipo, config] of Object.entries(URLS_OFICIALES)) {
    console.log(`\nüì° Procesando categor√≠a: ${tipo}`)

    try {
      const response = await fetch(config.url, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (compatible; ProfeFlow-Bot/1.0; +https://profeflow.cl)',
          'Accept': 'text/html,application/xhtml+xml',
          'Accept-Language': 'es-CL,es;q=0.9'
        }
      })

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`)
      }

      const html = await response.text()

      // Extraer PDFs por subcategor√≠a
      const pdfsPorSubcategoria = extraerPDFsPorSubcategoria(html, config.subcategorias)

      // Procesar cada PDF
      for (const [subcategoria, pdfLinks] of Object.entries(pdfsPorSubcategoria)) {
        console.log(`  üìÅ ${subcategoria}: ${pdfLinks.length} documentos`)

        for (const link of pdfLinks) {
          // Validaci√≥n b√°sica
          if (!link.url || !link.nombre) {
            console.log(`    ‚ö†Ô∏è  Link inv√°lido, saltando...`)
            continue
          }

          // 1. Intentar parsing b√°sico del nombre
          let metadata = parsearNombreArchivo(link.nombre, tipo, html)

          // 2. Si falla Y la IA est√° habilitada, usar clasificaci√≥n IA
          if (CONFIG.ENABLE_AI_CLASSIFICATION && (!metadata || (metadata as any).confianza < 0.7)) {
            console.log(`    ü§ñ Clasificaci√≥n IA para: ${link.nombre}`)
            const metadataIA = await retryWithBackoff(
              () => clasificarConIAMejorada(
                link,
                tipo,
                subcategoria,
                aiAnalyzer,
                pdfExtractor
              ),
              CONFIG.MAX_RETRIES,
              CONFIG.RETRY_DELAY_BASE,
              'Clasificaci√≥n IA'
            )

            if (metadataIA) {
              metadata = {
                a√±o: metadataIA.a√±o,
                nivel: metadataIA.nivel,
                modalidad: metadataIA.modalidad,
                asignatura: metadataIA.asignatura
              }
            }
          }

          // 3. Si todo falla, usar defaults inteligentes
          if (!metadata) {
            metadata = {
              a√±o: 2025,
              nivel: inferirNivelPorTipo(tipo),
              modalidad: 'regular'
            }
            console.log(`    ‚ÑπÔ∏è  Usando defaults (parsing b√°sico)`)
          }

          // Solo agregar si tiene a√±o reciente y metadata v√°lida
          // Incluimos desde 2023 para capturar r√∫bricas hist√≥ricas
          if (metadata && metadata.a√±o >= 2023) {
            documentosDetectados.push({
              nombre: link.nombre,
              url: link.url,
              tipo,
              subcategoria,
              a√±o: metadata.a√±o,
              nivel_educativo: metadata.nivel,
              modalidad: metadata.modalidad,
              asignatura: metadata.asignatura,
              confianza_clasificacion: 0.5 // Default si no es de IA
            })
          } else if (metadata) {
            console.log(`    ‚è≠Ô∏è  Documento antiguo (${metadata.a√±o}), saltando`)
          }

          // Rate limiting entre documentos
          await new Promise(r => setTimeout(r, CONFIG.DELAY_BETWEEN_DOCUMENTS))
        }
      }

      // Rate limiting entre categor√≠as
      await new Promise(r => setTimeout(r, CONFIG.DELAY_BETWEEN_CATEGORIES))

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Error desconocido'
      console.error(`  ‚ùå Error en ${tipo}:`, errorMessage)
    }
  }

  return documentosDetectados
}

/**
 * Normaliza URL removiendo par√°metros din√°micos (refresh, timestamps)
 * Mantiene solo base + wpdmdl (ID estable del documento)
 */
function normalizarUrl(url: string): string {
  try {
    const urlObj = new URL(url)
    // Extraer solo el par√°metro wpdmdl (ID estable del documento)
    const wpdmdl = urlObj.searchParams.get('wpdmdl')
    const basePath = urlObj.origin + urlObj.pathname
    // Retornar URL sin par√°metros din√°micos
    return wpdmdl ? `${basePath}?wpdmdl=${wpdmdl}` : basePath
  } catch {
    // Si falla el parsing, retornar URL original
    return url
  }
}

/**
 * Analiza documentos detectados vs base de datos
 */
async function analizarDocumentos(
  supabase: any,
  documentosDetectados: DocumentoDetectado[],
  pdfExtractor: PDFExtractor,
  aiAnalyzer: AIAnalyzer
): Promise<AnalisisDocumentos> {

  const resultado: AnalisisDocumentos = {
    nuevos: [],
    actualizados: [],
    duplicados: [],
    invalidos: []
  }

  for (const doc of documentosDetectados) {
    try {
      // Normalizar URL para comparaci√≥n
      const urlNormalizada = normalizarUrl(doc.url)
      
      // Buscar duplicados con estrategia mejorada
      // 1. Primero buscar por URL normalizada (sin par√°metros din√°micos)
      const { data: porUrl, error: errorUrl } = await supabase
        .from('documentos_oficiales')
        .select('id, hash_contenido, version, url_original, titulo, storage_path')
        .eq('url_original', urlNormalizada)
      
      if (errorUrl) {
        console.log(`  ‚ö†Ô∏è  Error buscando URL: ${errorUrl.message}`)
      }
      
      if (porUrl && porUrl.length > 0) {
        const existente = porUrl[0]
        
        // Si el documento NO tiene hash (pendiente de descarga), es duplicado
        if (!existente.hash_contenido) {
          resultado.duplicados.push(doc)
          continue
        }
        
        // Si tiene hash, verificar si cambi√≥ el contenido
        const hashNuevo = await calcularHashRemoto(doc.url)
        
        if (hashNuevo && hashNuevo !== existente.hash_contenido) {
          // ‚úÖ ACTUALIZADO
          resultado.actualizados.push({
            ...doc,
            id_existente: existente.id,
            version_anterior: existente.version,
            hash_nuevo: hashNuevo
          })
          console.log(`  üîÑ ${doc.nombre} (hash cambi√≥)`)
        } else {
          // ‚è≠Ô∏è DUPLICADO (mismo contenido)
          resultado.duplicados.push(doc)
        }
        
        continue // Ya procesado, siguiente documento
      }
      
      // 2. Si no hay match por URL, buscar por nombre exacto + a√±o
      const nombreNormalizado = doc.nombre
        .toLowerCase()
        .normalize('NFD')
        .replace(/[\u0300-\u036f]/g, '') // Eliminar tildes
        .replace(/[^a-z0-9]/g, '') // Solo alfanum√©ricos
      
      const { data: porNombre } = await supabase
        .from('documentos_oficiales')
        .select('id, hash_contenido, version, url_original, titulo, storage_path')
        .eq('a√±o_vigencia', doc.a√±o)
      
      // Filtrar por similitud de nombre (en memoria)
      const existentes = porNombre?.filter((existente: any) => {
        const tituloNormalizado = existente.titulo
          .toLowerCase()
          .normalize('NFD')
          .replace(/[\u0300-\u036f]/g, '')
          .replace(/[^a-z0-9]/g, '')
        
        // Match si > 80% de similitud
        const similitud = calcularSimilitud(nombreNormalizado, tituloNormalizado)
        return similitud > 0.8
      }) || []

      if (existentes.length === 0) {
        // ‚úÖ NUEVO
        resultado.nuevos.push(doc)
        console.log(`  üÜï ${doc.nombre}`)

      } else if (existentes.length === 1) {
        const existente = existentes[0]
        
        // Mismo t√≠tulo pero URL diferente (posible duplicado o re-publicaci√≥n)
        const urlExistenteNorm = normalizarUrl(existente.url_original)
        const urlNuevaNorm = normalizarUrl(doc.url)
        
        if (urlExistenteNorm !== urlNuevaNorm) {
          console.log(`  ‚ö†Ô∏è  URL diferente para: ${doc.nombre}`)
          console.log(`      BD (norm): ${urlExistenteNorm}`)
          console.log(`      Nuevo (norm): ${urlNuevaNorm}`)
        }
        
        resultado.duplicados.push(doc)

      } else {
        // M√∫ltiples coincidencias
        console.log(`  ‚ö†Ô∏è  ${existentes.length} coincidencias para: ${doc.nombre}`)
        resultado.duplicados.push(doc)
      }

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Error desconocido'
      console.error(`  ‚ùå Error analizando ${doc.nombre}:`, errorMessage)
      resultado.invalidos.push({ doc, error: errorMessage })
    }
  }

  return resultado
}

/**
 * Registra documentos nuevos en BD sin descargarlos (r√°pido)
 * Solo crea el registro con estado 'pendiente_descarga'
 */
async function registrarDocumentosNuevos(
  supabase: any,
  documentosNuevos: DocumentoDetectado[]
): Promise<any[]> {
  
  const registrados = []
  
  for (const doc of documentosNuevos) {
    try {
      // Obtener fuente DocenteMas
      const fuenteId = await obtenerOCrearFuenteDocenteMas(supabase)
      
      const { data, error } = await supabase
        .from('documentos_oficiales')
        .insert({
          fuente_id: fuenteId,
          tipo_documento: mapearTipoDocumento(doc.tipo, doc.subcategoria),
          nivel_educativo: doc.nivel_educativo,
          modalidad: doc.modalidad,
          asignatura: doc.asignatura || null,
          a√±o_vigencia: doc.a√±o,
          titulo: doc.nombre,
          url_original: normalizarUrl(doc.url),
          version: `${doc.a√±o}.1`,
          formato: 'pdf',
          procesado: false,
          es_version_actual: true,
          estado_procesamiento: 'pendiente', // Estado general
          etapa_actual: 'pendiente_descarga', // üÜï Etapa espec√≠fica del pipeline
          hash_contenido: null, // Se calcular√° durante la descarga
          storage_path: null, // Se asignar√° durante la descarga
          tama√±o_bytes: null, // Se asignar√° durante la descarga
          metadata: {
            subcategoria: doc.subcategoria,
            tipo_original: doc.tipo,
            confianza_clasificacion: doc.confianza_clasificacion
          }
        })
        .select()
        .single()
      
      if (error) {
        console.log(`  ‚ö†Ô∏è  Error registrando ${doc.nombre}: ${error.message}`)
        continue
      }
      
      registrados.push(data)
      
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Error desconocido'
      console.log(`  ‚ùå Error: ${errorMessage}`)
    }
  }
  
  return registrados
}

/**
 * Procesa documentos que ya est√°n en BD con estado 'pendiente_descarga'
 * Descarga PDF, sube a storage y actualiza registro
 */
async function procesarDocumentosPendientes(
  supabase: any,
  documentosPendientes: any[],
  processor: DocumentProcessor
): Promise<ResultadoProcesamiento[]> {
  
  const resultados: ResultadoProcesamiento[] = []
  
  // Procesamiento paralelo con l√≠mite de concurrencia
  const concurrencia = CONFIG.MAX_CONCURRENT_DOWNLOADS
  
  for (let i = 0; i < documentosPendientes.length; i += concurrencia) {
    const lote = documentosPendientes.slice(i, i + concurrencia)
    console.log(`\nüì¶ Lote ${Math.floor(i / concurrencia) + 1}/${Math.ceil(documentosPendientes.length / concurrencia)} (${lote.length} docs)`)
    
    const promesas = lote.map(async (doc) => {
      console.log(`  üì• ${doc.titulo}`)
      
      try {
        await descargarYActualizarDocumento(supabase, doc)
        console.log(`     ‚úÖ Completado`)
        return {
          documento: doc.titulo,
          exito: true,
          documento_id: doc.id
        }
      } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Error desconocido'
        console.error(`     ‚ùå Error: ${errorMessage}`)
        return {
          documento: doc.titulo,
          exito: false,
          error: errorMessage
        }
      }
    })
    
    const resultadosLote = await Promise.all(promesas)
    resultados.push(...resultadosLote)
  }
  
  return resultados
}

/**
 * Descarga PDF y actualiza documento en BD
 */
async function descargarYActualizarDocumento(supabase: any, doc: any): Promise<void> {
  
  // Marcar como procesando
  await supabase
    .from('documentos_oficiales')
    .update({ 
      estado_procesamiento: 'procesando',
      etapa_actual: 'descargando'
    })
    .eq('id', doc.id)
  
  // 1. Descargar PDF
  const response = await fetch(doc.url_original)
  if (!response.ok) {
    throw new Error(`HTTP ${response.status}: ${response.statusText}`)
  }
  
  const pdfBuffer = await response.arrayBuffer()
  const hash = await calcularHash(pdfBuffer)
  
  // 2. Subir a Supabase Storage
  const sanitizedName = doc.titulo
    .normalize('NFD')
    .replace(/[\u0300-\u036f]/g, '')
    .replace(/[^a-zA-Z0-9.\-_]/g, '_')
    .replace(/_+/g, '_')
    .replace(/^_|_$/g, '')
  
  const fileName = `${doc.tipo_documento}/${doc.a√±o_vigencia}/${sanitizedName}.pdf`
  
  await crearBucketSiNoExiste(supabase)
  
  const { error: uploadError } = await supabase.storage
    .from('documentos-oficiales')
    .upload(fileName, pdfBuffer, {
      contentType: 'application/pdf',
      upsert: true
    })
  
  if (uploadError) {
    throw new Error(`Error subiendo archivo: ${uploadError.message}`)
  }
  
  // 3. Actualizar registro en BD
  await supabase
    .from('documentos_oficiales')
    .update({
      storage_path: fileName,
      tama√±o_bytes: pdfBuffer.byteLength,
      hash_contenido: hash,
      estado_procesamiento: 'descargado',
      etapa_actual: 'descargado',
      fecha_descarga: new Date().toISOString()
    })
    .eq('id', doc.id)
}

/**
 * Procesa documentos nuevos en lotes con paralelismo controlado
 */
async function procesarDocumentosNuevos(
  supabase: any,
  documentosNuevos: DocumentoDetectado[],
  processor: DocumentProcessor
): Promise<ResultadoProcesamiento[]> {
  
  const resultados: ResultadoProcesamiento[] = []
  
  // Limitar procesamiento por ejecuci√≥n para evitar timeout
  const documentosAProcesar = documentosNuevos.slice(0, CONFIG.MAX_DOCS_PER_EXECUTION)
  const documentosPendientes = documentosNuevos.length - documentosAProcesar.length
  
  if (documentosPendientes > 0) {
    console.log(`\n‚ö†Ô∏è  Procesando ${documentosAProcesar.length} de ${documentosNuevos.length} documentos`)
    console.log(`   ${documentosPendientes} documentos quedar√°n pendientes para pr√≥xima ejecuci√≥n`)
  }
  
  // Procesamiento paralelo con l√≠mite de concurrencia
  const concurrencia = CONFIG.MAX_CONCURRENT_DOWNLOADS
  
  for (let i = 0; i < documentosAProcesar.length; i += concurrencia) {
    const lote = documentosAProcesar.slice(i, i + concurrencia)
    console.log(`\nÔøΩ Procesando lote ${Math.floor(i / concurrencia) + 1}/${Math.ceil(documentosAProcesar.length / concurrencia)} (${lote.length} docs)`)
    
    // Procesar lote en paralelo
    const promesas = lote.map(async (doc) => {
      console.log(`  üì• ${doc.nombre}`)
      
      try {
        const resultado = await procesarDocumentoNuevo(supabase, doc, processor)
        console.log(`     ‚úÖ Completado`)
        return resultado
      } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Error desconocido'
        console.error(`     ‚ùå Error: ${errorMessage}`)
        return {
          documento: doc.nombre,
          exito: false,
          error: errorMessage
        }
      }
    })
    
    const resultadosLote = await Promise.all(promesas)
    resultados.push(...resultadosLote)
  }
  
  return resultados
}

/**
 * Procesa actualizaciones de documentos
 */
async function procesarActualizaciones(
  supabase: any,
  documentosActualizados: DocumentoActualizado[]
): Promise<void> {
  
  for (const doc of documentosActualizados) {
    console.log(`\nüîÑ Procesando actualizaci√≥n: ${doc.nombre}`)
    
    try {
      await procesarActualizacionDocumento(supabase, doc)
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Error desconocido'
      console.error(`  ‚úó Error procesando actualizaci√≥n:`, errorMessage)
    }
  }
}

/**
 * Genera reporte final
 */
function generarReporte(
  documentosDetectados: DocumentoDetectado[],
  analisis: AnalisisDocumentos,
  resultados: ResultadoProcesamiento[],
  tiempoMs: number,
  pipelinePendientes: number,
  pipelineDescargados: number
): Reporte {
  const documentosNuevosProcesados = resultados.filter(r => !r.actualizado).length
  const documentosNuevosPendientes = Math.max(0, analisis.nuevos.length - documentosNuevosProcesados)
  
  const actualizacionesProcesadas = resultados.filter(r => r.actualizado).length
  const actualizacionesPendientes = Math.max(0, analisis.actualizados.length - actualizacionesProcesadas)
  
  return {
    fecha_monitoreo: new Date().toISOString(),
    documentos_detectados: documentosDetectados.length,
    documentos_nuevos: analisis.nuevos.length,
    documentos_nuevos_procesados: documentosNuevosProcesados,
    documentos_nuevos_pendientes: documentosNuevosPendientes,
    documentos_actualizados: analisis.actualizados.length,
    documentos_actualizados_procesados: actualizacionesProcesadas,
    documentos_actualizados_pendientes: actualizacionesPendientes,
    documentos_duplicados: analisis.duplicados.length,
    documentos_invalidos: analisis.invalidos.length,
    procesamiento_exitoso: resultados.filter(r => r.exito).length,
    procesamiento_fallido: resultados.filter(r => !r.exito).length,
    tiempo_total_ms: tiempoMs,
    pipeline_pendientes_descarga: pipelinePendientes,
    pipeline_descargados: pipelineDescargados,
    pipeline_total: pipelinePendientes + pipelineDescargados,
    detalles: resultados
  }
}

// ============================================
// FUNCIONES AUXILIARES
// ============================================

function extraerPDFsPorSubcategoria(
  html: string, 
  subcategorias: string[]
): Record<string, Array<{ nombre: string; url: string }>> {
  const resultado: Record<string, Array<{ nombre: string; url: string }>> = {}
  
  // Inicializar resultado
  for (const subcategoria of subcategorias) {
    resultado[subcategoria] = []
  }
  
  // ESTRATEGIA: Extraer TODOS los PDFs primero, luego clasificar por URL/nombre
  const todosPDFs = extraerLinksPDF(html)
  
  console.log(`      üìÑ Total PDFs encontrados: ${todosPDFs.length}`)
  
  // Clasificar cada PDF por su URL/nombre
  for (const pdf of todosPDFs) {
    const urlLower = pdf.url.toLowerCase()
    const nombreLower = pdf.nombre.toLowerCase()
    const textoCompleto = `${urlLower} ${nombreLower}`
    
    let subcategoriaAsignada = subcategorias[0] // Default
    
    // Patrones de clasificaci√≥n basados en URL/nombre
    const clasificadores: Record<string, RegExp[]> = {
      'Programas EMTP': [
        /programa.*estudio.*especialidad/i,
        /emtp/i,
        /tecnico.*profesional/i,
        /especialidad-/i
      ],
      'Priorizaci√≥n Curricular': [
        /priorizacion/i,
        /priorizaci[o√≥]n/i,
        /actualizacion.*priorizacion/i
      ],
      'Marco para la Buena Ense√±anza': [
        /marco.*buena.*ensenanza/i,
        /marco.*buena.*ense√±anza/i,
        /mbe/i,
        /\/marco-para-la-buena/i
      ],
      'Bases curriculares': [
        /bases.*curriculares/i,
        /programa.*estudio(?!.*especialidad)/i, // Programa de estudio (no especialidad)
        /curricul/i
      ],
      'R√∫bricas Portafolio': [
        /rubrica/i,
        /r√∫brica/i,
        /evaluacion.*docente/i
      ]
    }
    
    // Buscar match
    for (const [subcategoria, patrones] of Object.entries(clasificadores)) {
      if (subcategorias.includes(subcategoria)) {
        if (patrones.some(patron => patron.test(textoCompleto))) {
          subcategoriaAsignada = subcategoria
          break
        }
      }
    }
    
    // Agregar a la subcategor√≠a correspondiente
    if (!resultado[subcategoriaAsignada]) {
      resultado[subcategoriaAsignada] = []
    }
    resultado[subcategoriaAsignada].push(pdf)
  }
  
  // Mostrar resumen
  for (const [subcategoria, pdfs] of Object.entries(resultado)) {
    if (pdfs.length > 0) {
      console.log(`      üìÅ ${subcategoria}: ${pdfs.length} PDFs`)
    }
  }
  
  return resultado
}

function extraerLinksPDF(html: string): Array<{ nombre: string; url: string }> {
  const links: Array<{ nombre: string; url: string }> = []
  const baseUrl = 'https://www.docentemas.cl'
  
  // Patr√≥n principal: data-downloadurl con WordPress Download Manager
  const patronDataDownload = /<div[^>]*>.*?<a[^>]*data-downloadurl=["']([^"']*)["'][^>]*>([^<]*)<\/a>.*?<\/div>/gis
  
  let match
  while ((match = patronDataDownload.exec(html)) !== null) {
    const url = match[1].replace(/&amp;/g, '&') // Decodificar HTML entities
    const textoBoton = match[2].trim()
    const contextoDiv = match[0] // Todo el div para extraer m√°s contexto
    
    // Extraer nombre mejorado con contexto
    const nombre = extraerNombreConContexto(url, textoBoton, contextoDiv)
    
    if (url && !links.some(l => l.url === url)) {
      links.push({
        nombre,
        url: url.startsWith('http') ? url : new URL(url, baseUrl).href
      })
    }
  }
  
  // Patrones adicionales como fallback
  const patronesAdicionales = [
    // Enlaces directos a PDF
    /href=["']([^"']*\.pdf[^"']*)["'][^>]*>([^<]*)<\/a>/gi,
    // WordPress Download Manager en href
    /href=["']([^"']*\?wpdmdl=\d+[^"']*)["'][^>]*>([^<]*)<\/a>/gi
  ]
  
  for (const patron of patronesAdicionales) {
    while ((match = patron.exec(html)) !== null) {
      const url = match[1].replace(/&amp;/g, '&')
      const nombre = (match[2] || extraerNombreDeUrl(url) || '').trim()
      
      if (nombre && !links.some(l => l.url === url)) {
        links.push({
          nombre,
          url: url.startsWith('http') ? url : new URL(url, baseUrl).href
        })
      }
    }
  }
  
  return links
}

function extraerNombreDeUrl(url: string): string {
  // Para URLs con wpdmdl, intentar extraer el slug descriptivo
  if (url.includes('wpdmdl=')) {
    // Patr√≥n: https://www.docentemas.cl/download/nombre-descriptivo/?wpdmdl=123
    const slugMatch = url.match(/\/download\/([^/?]+)\//i)
    if (slugMatch && slugMatch[1]) {
      const slug = slugMatch[1]
        .replace(/-/g, ' ')  // Convertir guiones en espacios
        .replace(/_/g, ' ')  // Convertir underscores en espacios
        .split(' ')
        .map(word => word.charAt(0).toUpperCase() + word.slice(1)) // Capitalizar
        .join(' ')
        .trim()
      
      if (slug && slug.length > 3) {
        return slug
      }
    }
    
    // Fallback: usar ID si no hay slug
    const id = url.match(/wpdmdl=(\d+)/)?.[1]
    return id ? `documento_${id}` : 'documento'
  }
  
  // Para URLs directas, usar el nombre del archivo
  return url.split('/').pop()?.split('?')[0] || 'documento'
}

function extraerNombreConContexto(url: string, textoBoton: string, contextoHtml: string): string {
  // Buscar t√≠tulos o descripciones en el contexto HTML
  const patronTitulo = /<h[1-6][^>]*>([^<]+)<\/h[1-6]>/i
  const patronDescripcion = /<p[^>]*>([^<]+)<\/p>/i
  const patronStrong = /<strong[^>]*>([^<]+)<\/strong>/i
  
  const matchTitulo = contextoHtml.match(patronTitulo)
  const matchDescripcion = contextoHtml.match(patronDescripcion)
  const matchStrong = contextoHtml.match(patronStrong)
  
  // Priorizar t√≠tulo, luego descripci√≥n, luego texto del bot√≥n
  const nombreContexto = matchTitulo?.[1]?.trim() || 
                         matchStrong?.[1]?.trim() ||
                         matchDescripcion?.[1]?.trim() ||
                         textoBoton

  // Si encontramos contexto √∫til, usarlo; sino usar URL
  if (nombreContexto && nombreContexto !== 'Descargar' && nombreContexto.length > 5) {
    return nombreContexto.replace(/[^a-zA-Z0-9√Ä-≈ø\s\-_]/g, '').trim()
  }

  return extraerNombreDeUrl(url)
}

function parsearNombreArchivo(nombre: string, tipo?: string, html?: string): {
  a√±o: number
  nivel: string
  modalidad: string
  asignatura?: string
} | null {

  const nombreLower = nombre.toLowerCase()

  // Detectar a√±o con m√∫ltiples patrones (incluye 2023-2026)
  const a√±oMatch = nombre.match(/202[3-9]/) || nombre.match(/\b(2023|2024|2025|2026)\b/)
  const a√±o = a√±oMatch ? parseInt(a√±oMatch[0]) : 2025 // Default a 2025 si no se encuentra

  // Patrones mejorados para nivel educativo
  let nivel = 'regular'
  const patronesNivel = {
    'parvularia': /parvularia|p√°rvulo|pre\s*escolar|educaci√≥n parvularia|educacion parvularia/,
    'basica_1_6': /1¬∞?\s*a\s*6¬∞?|b√°sica.*1.*6|primero.*sexto/,
    'basica_7_8_media': /7¬∞?.*8¬∞?|s√©ptimo.*octavo|media|secundaria/,
    'media_tp': /t√©cnico\s*profesional|tp|medio.*t√©cnico/,
    'especial_regular': /especial.*regular|integraci√≥n/,
    'especial_neep': /especial.*neep|escuela.*especial/,
    'hospitalaria': /hospitalaria|hospital/,
    'encierro': /encierro|c√°rcel|penitenciar/,
    'lengua_indigena': /lengua.*ind√≠gena|mapuche|quechua|aymara/,
    'epja': /adultos|j√≥venes.*adultas|epja/
  }

  for (const [key, patron] of Object.entries(patronesNivel)) {
    if (patron.test(nombreLower)) {
      nivel = key
      break
    }
  }

  // Detectar modalidad
  let modalidad = 'regular'
  if (/especial/.test(nombreLower)) modalidad = 'especial'
  if (/hospitalaria/.test(nombreLower)) modalidad = 'hospitalaria'
  if (/encierro/.test(nombreLower)) modalidad = 'encierro'
  if (/lengua.*ind√≠gena/.test(nombreLower)) modalidad = 'lengua_indigena'

  // Detectar asignatura desde nombre del archivo
  let asignatura: string | undefined
  const patronesAsignatura = {
    'Matem√°tica': /matem√°tica|matem√°ticas|matematica|matematicas|matem_ticas/i,
    'Lenguaje y Comunicaci√≥n': /lenguaje|comunicaci√≥n|comunicacion|comunicaci_n|lengua castellana|castellano/i,
    'Ciencias Naturales': /ciencias naturales|biolog√≠a|biolog_a|biologia|f√≠sica|fisica|f_sica|qu√≠mica|quimica|qu_mica/i,
    'Historia y Geograf√≠a': /historia|geograf√≠a|geografia|ciencias sociales|sociales/i,
    'Ingl√©s': /ingl√©s|ingles|ingl_s|english/i,
    'Artes Visuales': /artes visuales|artes_visuales|artes pl√°sticas|artes plasticas|artes_plasticas|artes_pl_sticas/i,
    'M√∫sica': /m√∫sica|musica|artes musicales/i,
    'Educaci√≥n F√≠sica': /educaci√≥n f√≠sica|educacion fisica|educacion_fisica|educaci_n_f_sica|ed\. f√≠sica|ed_f_sica|ed\. fisica/i,
    'Tecnolog√≠a': /tecnolog√≠a|tecnologia|tecnolog_a/i,
    'Religi√≥n': /religi√≥n|religion|religi_on|cat√≥lica|catolica|cat_lica|evangelica|evang√©lica|evang_lica/i
  }

  for (const [asig, patron] of Object.entries(patronesAsignatura)) {
    if (patron.test(nombreLower)) {
      asignatura = asig
      break
    }
  }

  return { a√±o, nivel, modalidad, asignatura }
}

/**
 * Clasificaci√≥n IA MEJORADA - con contenido real del PDF
 */
async function clasificarConIAMejorada(
  link: { nombre: string; url: string },
  tipo: string,
  subcategoria: string,
  aiAnalyzer: AIAnalyzer,
  pdfExtractor: PDFExtractor
): Promise<ClasificacionMetadata | null> {

  try {
    // 1. Validar que es PDF y obtener metadata
    const headResponse = await fetch(link.url, { 
      method: 'HEAD',
      headers: {
        'User-Agent': 'Mozilla/5.0 (compatible; ProfeFlow-Bot/1.0)'
      }
    })
    
    if (!headResponse.ok) {
      console.log(`      ‚ö†Ô∏è  No accesible (HTTP ${headResponse.status})`)
      return null
    }
    
    const contentType = headResponse.headers.get('content-type')
    const contentLength = parseInt(headResponse.headers.get('content-length') || '0')
    
    if (!contentType?.includes('pdf')) {
      console.log(`      ‚ö†Ô∏è  No es PDF (${contentType})`)
      return null
    }
    
    if (contentLength < CONFIG.MIN_PDF_SIZE || contentLength > CONFIG.MAX_PDF_SIZE) {
      console.log(`      ‚ö†Ô∏è  Tama√±o inv√°lido (${(contentLength / 1024).toFixed(2)} KB)`)
      return null
    }
    
    // 2. Descargar y extraer texto de primeras p√°ginas
    console.log(`      üì• Descargando muestra (${(contentLength / 1024).toFixed(2)} KB)...`)
    
    // Crear AbortController con timeout
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), CONFIG.PDF_DOWNLOAD_TIMEOUT)
    
    try {
      const response = await fetch(link.url, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (compatible; ProfeFlow-Bot/1.0)',
          'Range': `bytes=0-${Math.min(contentLength, CONFIG.PDF_SAMPLE_SIZE)}`
        },
        signal: controller.signal
      })
      
      clearTimeout(timeoutId)
      
      const pdfBuffer = await response.arrayBuffer()
      
      // Extraer texto de primeras p√°ginas
      const textoMuestra = await pdfExtractor.extractFirstPages(
        pdfBuffer,
        CONFIG.PDF_SAMPLE_PAGES
      )
      
      if (!textoMuestra || textoMuestra.length < 100) {
        console.log(`      ‚ö†Ô∏è  No se pudo extraer texto suficiente`)
        return null
      }
      
      console.log(`      ‚úì Texto extra√≠do: ${textoMuestra.length} chars`)
      
      // Limitar texto a m√°ximo 1500 caracteres para evitar exceder contexto de IA
      const textoLimitado = textoMuestra.substring(0, 1500)
      
      // 3. Clasificar con IA usando contenido real
      const prompt = `Clasifica este documento educativo chileno del MINEDUC.

**CONTEXTO:**
- Categor√≠a: ${tipo}
- Subcategor√≠a: ${subcategoria}
- Nombre archivo: ${link.nombre}

**CONTENIDO (primeras p√°ginas):**
${textoLimitado}

**INSTRUCCIONES:**
Analiza el contenido y clasifica el documento. Responde SOLO con JSON v√°lido (sin markdown):

{
  "a√±o": n√∫mero entre 2023-2026 (busca en encabezados, pie de p√°gina, o contenido),
  "justificacion_a√±o": "explica de d√≥nde se obtuvo el a√±o (ej: 'Encabezado dice 2025', 'Decreto 67/2018')",
  "nivel_educativo": "parvularia|basica_1_6|basica_7_8_media|media_tp|especial_regular|especial_neep|hospitalaria|encierro|lengua_indigena|epja|regular",
  "justificacion_nivel": "explica por qu√© este nivel (ej: 'Menciona 1¬∞ a 6¬∞ b√°sico', 'Documento para TP')",
  "modalidad": "regular|especial|hospitalaria|encierro|lengua_indigena",
  "asignatura": "Matem√°tica|Lenguaje y Comunicaci√≥n|Historia y Geograf√≠a|Ciencias Naturales|Ingl√©s|Artes Visuales|M√∫sica|Educaci√≥n F√≠sica|Tecnolog√≠a|Religi√≥n|null",
  "confianza": 0.0 a 1.0 (qu√© tan seguro est√°s de la clasificaci√≥n),
  "razonamiento": "resumen breve del an√°lisis (max 100 palabras)"
}

**NOTAS:**
- Si no encuentras a√±o expl√≠cito, usa contexto (ej: "Priorizaci√≥n 2020-2022" = 2020)
- Si el documento menciona m√∫ltiples niveles, elige el m√°s prominente
- confianza < 0.7 solo si hay mucha ambig√ºedad`
    
    const resultadoIA = await aiAnalyzer.clasificarDocumento(prompt)
    
    // 4. Validar respuesta de IA
    const clasificacion = validarRespuestaIA(resultadoIA)
    
    if (!clasificacion) {
      console.log(`      ‚ö†Ô∏è  Respuesta IA inv√°lida`)
      return null
    }
    
    if (clasificacion.confianza < CONFIG.MIN_AI_CONFIDENCE) {
      console.log(`      ‚ö†Ô∏è  Confianza baja (${clasificacion.confianza})`)
      return null
    }
    
    console.log(`      ‚úÖ Clasificado: ${clasificacion.nivel_educativo} (${clasificacion.confianza})`)
    if (clasificacion.justificacion_a√±o) {
      console.log(`         üìÖ A√±o: ${clasificacion.justificacion_a√±o}`)
    }
    if (clasificacion.justificacion_nivel) {
      console.log(`         üéì Nivel: ${clasificacion.justificacion_nivel}`)
    }
    
    return {
      a√±o: clasificacion.a√±o,
      nivel: clasificacion.nivel_educativo,
      modalidad: clasificacion.modalidad,
      asignatura: clasificacion.asignatura,
      confianza: clasificacion.confianza
    }
    
    } catch (downloadError) {
      clearTimeout(timeoutId)
      const errorMessage = downloadError instanceof Error ? downloadError.message : 'Error desconocido'
      if (downloadError instanceof Error && downloadError.name === 'AbortError') {
        console.log(`      ‚ö†Ô∏è  Timeout descargando PDF (>${CONFIG.PDF_DOWNLOAD_TIMEOUT}ms)`)
      } else {
        console.log(`      ‚ùå Error descargando PDF: ${errorMessage}`)
      }
      return null
    }
    
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Error desconocido'
    console.log(`      ‚ùå Error clasificaci√≥n IA: ${errorMessage}`)
    return null
  }
}

/**
 * Valida respuesta de IA y extrae JSON
 */
function validarRespuestaIA(resultado: any): any | null {
  try {
    // Si es string, intentar parsear JSON
    let data = resultado
    if (typeof resultado === 'string') {
      // Limpiar markdown si est√° presente
      const jsonMatch = resultado.match(/```json\n?([\s\S]*?)\n?```/) || 
                       resultado.match(/\{[\s\S]*\}/)
      
      if (jsonMatch) {
        data = JSON.parse(jsonMatch[1] || jsonMatch[0])
      } else {
        return null
      }
    }
    
    // Validar campos requeridos
    if (!data.a√±o || !data.nivel_educativo || !data.confianza) {
      return null
    }
    
    // Validar rangos (incluye 2023 para r√∫bricas hist√≥ricas)
    if (data.a√±o < 2023 || data.a√±o > 2026) {
      return null
    }
    
    if (data.confianza < 0 || data.confianza > 1) {
      return null
    }
    
    // Validar valores de nivel educativo
    const nivelesValidos = [
      'parvularia', 'basica_1_6', 'basica_7_8_media', 'media_tp',
      'especial_regular', 'especial_neep', 'hospitalaria', 'encierro',
      'lengua_indigena', 'epja', 'regular'
    ]
    
    if (!nivelesValidos.includes(data.nivel_educativo)) {
      return null
    }
    
    return data
    
  } catch (error) {
    console.error('Error validando respuesta IA:', error)
    return null
  }
}

/**
 * Calcula similitud entre dos strings usando coeficiente de S√∏rensen‚ÄìDice
 * M√°s r√°pido que Levenshtein y suficiente para nombres de documentos
 * Retorna valor entre 0 (totalmente diferentes) y 1 (id√©nticos)
 */
function calcularSimilitud(str1: string, str2: string): number {
  if (str1 === str2) return 1.0
  if (str1.length < 2 || str2.length < 2) return 0.0
  
  // Crear bigramas (pares de caracteres consecutivos)
  const bigramas1 = new Set<string>()
  const bigramas2 = new Set<string>()
  
  for (let i = 0; i < str1.length - 1; i++) {
    bigramas1.add(str1.substring(i, i + 2))
  }
  
  for (let i = 0; i < str2.length - 1; i++) {
    bigramas2.add(str2.substring(i, i + 2))
  }
  
  // Calcular intersecci√≥n
  let interseccion = 0
  for (const bigrama of bigramas1) {
    if (bigramas2.has(bigrama)) {
      interseccion++
    }
  }
  
  // Coeficiente de Dice: 2 * intersecci√≥n / (tama√±o1 + tama√±o2)
  return (2.0 * interseccion) / (bigramas1.size + bigramas2.size)
}

function inferirNivelPorTipo(tipo: string): string {
  // Inferir nivel educativo basado en el tipo de documento
  const mapeoNivel: Record<string, string> = {
    'manuales': 'regular',
    'rubricasPortafolio': 'regular', // R√∫bricas de evaluaci√≥n docente (todos los niveles)
    'referentesCurriculares': 'basica_1_6',
    'tiposDeInformesDeResultados': 'regular',
    'documentos': 'regular',
    'documentosLegales': 'regular'
  }
  return mapeoNivel[tipo] || 'regular'
}

async function calcularHashRemoto(url: string): Promise<string | null> {
  try {
    const response = await fetch(url)
    const arrayBuffer = await response.arrayBuffer()
    const hashBuffer = await crypto.subtle.digest('SHA-256', arrayBuffer)
    const hashArray = Array.from(new Uint8Array(hashBuffer))
    const hashHex = hashArray.map(b => b.toString(16).padStart(2, '0')).join('')
    return hashHex
  } catch (error) {
    console.error('Error calculando hash:', error)
    return null
  }
}

/**
 * Obtiene o crea la fuente DocenteMas en la BD
 */
async function obtenerOCrearFuenteDocenteMas(supabase: any): Promise<string> {
  // Intentar obtener fuente existente
  const { data: fuente } = await supabase
    .from('fuentes_documentacion')
    .select('id')
    .eq('nombre', 'DocenteMas')
    .maybeSingle()
  
  if (fuente?.id) {
    return fuente.id
  }
  
  // Crear nueva fuente
  console.log('  üìÅ Creando fuente DocenteMas...')
  const { data: nuevaFuente, error: insertError } = await supabase
    .from('fuentes_documentacion')
    .insert({
      nombre: 'DocenteMas',
      url_base: 'https://www.docentemas.cl',
      tipo_fuente: 'sitio_web',
      activo: true,
      patron_url: 'https://www.docentemas.cl/documentos-descargables/*',
      frecuencia_check: '1 day'
    })
    .select('id')
    .single()
  
  if (insertError || !nuevaFuente?.id) {
    throw new Error(`Error creando fuente: ${insertError?.message || 'ID nulo'}`)
  }
  
  return nuevaFuente.id
}

export async function procesarDocumentoNuevo(
  supabase: any,
  doc: DocumentoDetectado,
  processor?: DocumentProcessor
): Promise<any> {
  
  // Verificaci√≥n final de duplicados antes de procesar
  const { data: duplicado } = await supabase
    .from('documentos_oficiales')
    .select('id')
    .eq('url_original', doc.url)
    .maybeSingle()
  
  if (duplicado) {
    console.log('  ‚è≠Ô∏è  Documento ya existe, saltando...')
    return {
      documento: doc.nombre,
      exito: true,
      documento_id: duplicado.id,
      duplicado: true
    }
  }
  
  // 1. Descargar PDF
  console.log('  üì• Descargando PDF...')
  const response = await fetch(doc.url)
  if (!response.ok) {
    throw new Error(`HTTP ${response.status}: ${response.statusText}`)
  }
  
  const pdfBuffer = await response.arrayBuffer()
  const hash = await calcularHash(pdfBuffer)
  
  console.log(`  ‚úì Descargado: ${(pdfBuffer.byteLength / 1024).toFixed(2)} KB`)
  
  // Verificar duplicado por hash
  const { data: duplicadoHash } = await supabase
    .from('documentos_oficiales')
    .select('id, titulo')
    .eq('hash_contenido', hash)
    .maybeSingle()
  
  if (duplicadoHash) {
    console.log(`  ‚è≠Ô∏è  Contenido duplicado de: ${duplicadoHash.titulo}`)
    return {
      documento: doc.nombre,
      exito: true,
      documento_id: duplicadoHash.id,
      duplicado: true
    }
  }
  
  // 2. Subir a Supabase Storage
  // Sanitizar nombre de archivo: normalizar tildes y caracteres especiales
  const sanitizedName = doc.nombre
    .normalize('NFD') // Descomponer caracteres con tildes (√° ‚Üí a + ¬¥)
    .replace(/[\u0300-\u036f]/g, '') // Eliminar marcas diacr√≠ticas (tildes)
    .replace(/[^a-zA-Z0-9.\-_]/g, '_') // Solo permitir alfanum√©ricos, punto, gui√≥n y underscore
    .replace(/_+/g, '_') // Colapsar m√∫ltiples underscores consecutivos
    .replace(/^_|_$/g, '') // Eliminar underscores al inicio/final
  
  const fileName = `${doc.tipo}/${doc.a√±o}/${sanitizedName}.pdf`
  console.log(`  üíæ Subiendo a storage: ${fileName}`)
  
  await crearBucketSiNoExiste(supabase)
  
  const { error: uploadError } = await supabase.storage
    .from('documentos-oficiales')
    .upload(fileName, pdfBuffer, {
      contentType: 'application/pdf',
      upsert: true
    })
  
  if (uploadError) {
    throw new Error(`Error subiendo archivo: ${uploadError.message}`)
  }
  
  console.log('  ‚úì Subido a storage')
  
  // 3. Registrar en base de datos
  console.log('  üìù Registrando en BD...')
  
  // Obtener o crear fuente DocenteMas
  const fuenteId = await obtenerOCrearFuenteDocenteMas(supabase)
  console.log(`  üìù Usando fuente_id: ${fuenteId}`)
  
  const { data: documentoRegistrado, error: dbError } = await supabase
    .from('documentos_oficiales')
    .insert({
      fuente_id: fuenteId,
      tipo_documento: mapearTipoDocumento(doc.tipo, doc.subcategoria),
      nivel_educativo: doc.nivel_educativo,
      modalidad: doc.modalidad,
      asignatura: doc.asignatura || null,
      a√±o_vigencia: doc.a√±o,
      titulo: doc.nombre,
      url_original: normalizarUrl(doc.url), // URL sin par√°metros din√°micos (refresh, etc)
      storage_path: fileName,
      tama√±o_bytes: pdfBuffer.byteLength,
      hash_contenido: hash,
      version: `${doc.a√±o}.1`,
      formato: 'pdf',
      procesado: false,
      es_version_actual: true,
      estado_procesamiento: 'pendiente',
      etapa_actual: 'descargado',  // Ya est√° descargado y en Storage
      fecha_descarga: new Date().toISOString(),
      metadata: {
        subcategoria: doc.subcategoria,
        tipo_original: doc.tipo
      }
    })
    .select()
    .single()

  if (dbError) {
    throw new Error(`Error en BD: ${dbError.message}`)
  }

  console.log(`  ‚úÖ Documento registrado: ${documentoRegistrado.id}`)
  
  return {
    documento: doc.nombre,
    exito: true,
    documento_id: documentoRegistrado.id
  }
}

async function procesarActualizacionDocumento(
  supabase: any,
  doc: any
): Promise<void> {
  
  // 1. Marcar versi√≥n anterior como no actual
  await supabase
    .from('documentos_oficiales')
    .update({ es_version_actual: false })
    .eq('id', doc.id_existente)
  
  // 2. Crear nueva versi√≥n
  const nuevaVersion = incrementarVersion(doc.version_anterior)
  await procesarDocumentoNuevo(supabase, {
    ...doc,
    version: nuevaVersion
  })
  
  // 3. Registrar cambio
  const { data: cambio } = await supabase
    .from('cambios_documentos')
    .insert({
      documento_id: doc.id_existente,
      version_anterior: doc.version_anterior,
      version_nueva: nuevaVersion,
      cambios_detectados: [],
      tipo_cambio: 'moderado' // Se determinar√° en el procesamiento
    })
    .select()
    .single()
  
  console.log(`  ‚úì Cambio registrado: ${doc.version_anterior} ‚Üí ${nuevaVersion}`)
}

function mapearTipoDocumento(tipo: string, subcategoria?: string): string {
  // Mapeo por subcategor√≠a (m√°s espec√≠fico)
  if (subcategoria) {
    const mapeoSubcategoria: Record<string, string> = {
      'Bases curriculares': 'bases_curriculares',
      'Priorizaci√≥n Curricular': 'priorizacion_curricular',
      'Programas EMTP': 'programa_emtp',
      'Marco para la Buena Ense√±anza': 'marco_buena_ensenanza',
      'R√∫bricas Portafolio': 'rubricas_portafolio', // R√∫bricas de evaluaci√≥n docente
      'Manuales de Instrumentos': 'manual_portafolio',
      'Informes de Resultados': 'informe_resultados',
      'Documentos Legales': 'documento_legal'
    }
    
    if (mapeoSubcategoria[subcategoria]) {
      return mapeoSubcategoria[subcategoria]
    }
  }
  
  // Mapeo por tipo (fallback)
  const mapeo: Record<string, string> = {
    'manuales': 'manual_portafolio',
    'basesCurriculares': 'bases_curriculares',
    'rubricasPortafolio': 'rubricas_portafolio', // R√∫bricas de evaluaci√≥n docente
    'tiposDeInformesDeResultados': 'informe_resultados',
    'documentosLegales': 'documento_legal'
  }
  return mapeo[tipo] || 'instructivo'
}

function incrementarVersion(versionAnterior: string): string {
  const partes = versionAnterior.split('.')
  const minor = parseInt(partes[1] || '0') + 1
  return `${partes[0]}.${minor}`
}

async function calcularHash(buffer: ArrayBuffer): Promise<string> {
  const hashBuffer = await crypto.subtle.digest('SHA-256', buffer)
  const hashArray = Array.from(new Uint8Array(hashBuffer))
  return hashArray.map(b => b.toString(16).padStart(2, '0')).join('')
}

async function notificarAdministradores(supabase: any, reporte: any): Promise<void> {
  console.log('üìß Notificando a administradores...')
  
  // Crear notificaci√≥n en tiempo real
  const notificacion = {
    tipo: 'cambios_documentos',
    titulo: `${reporte.documentos_nuevos + reporte.documentos_actualizados} documentos actualizados`,
    mensaje: `Nuevos: ${reporte.documentos_nuevos}, Actualizados: ${reporte.documentos_actualizados}`,
    fecha: reporte.fecha_monitoreo,
    prioridad: reporte.documentos_nuevos > 0 ? 'alta' : 'media',
    metadata: reporte
  }
  
  // Insertar en tabla de notificaciones
  await supabase.from('notificaciones_admin').insert(notificacion)
  
  // Enviar por canal en tiempo real
  await supabase
    .channel('admin-notifications')
    .send({
      type: 'broadcast',
      event: 'documento_cambio',
      payload: notificacion
    })
  
  console.log('  ‚úì Notificaci√≥n enviada')
}

async function crearBucketSiNoExiste(supabase: any): Promise<void> {
  try {
    // Verificar si el bucket existe
    const { data: buckets } = await supabase.storage.listBuckets()
    const bucketExiste = buckets?.some((bucket: any) => bucket.name === 'documentos-oficiales')
    
    if (!bucketExiste) {
      console.log('  üìÅ Creando bucket documentos-oficiales...')
      const { error } = await supabase.storage.createBucket('documentos-oficiales', {
        public: false,
        allowedMimeTypes: ['application/pdf'],
        fileSizeLimit: 50 * 1024 * 1024 // 50MB
      })
      
      if (error) {
        console.warn('  ‚ö†Ô∏è  Error creando bucket:', error.message)
      } else {
        console.log('  ‚úì Bucket creado exitosamente')
      }
    }
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Error desconocido'
    console.warn('  ‚ö†Ô∏è  Error verificando bucket:', errorMessage)
  }
}